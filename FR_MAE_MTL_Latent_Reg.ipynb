{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4173c20e-19af-4b0c-ae90-acffa873adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f8697f-dd0e-45ad-b441-06259fcccfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('outputs/run', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7fa16-8867-4f7b-a0a5-fea09a0cd05f",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e759250-6143-44e5-91e8-18ab147380fc",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b29ccbb-bfff-455d-9363-c843f2e0240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_the_data(data_dir):\n",
    "    # Generate data paths with labels\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    # Get folder names\n",
    "    folds = os.listdir(data_dir)\n",
    "\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(data_dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            \n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Concatenate data paths with labels into one DataFrame\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3055c21-3c9b-42dc-9fba-6154c973c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths labels\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...   High\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...   High\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...   High\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...   High\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...   High\n",
       "...                                                  ...    ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...  Water\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...  Water\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...  Water\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...  Water\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...  Water\n",
       "\n",
       "[70331 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = 'G:\\\\FireRisk'\n",
    "\n",
    "train_df = loading_the_data(dir + '\\\\train')\n",
    "test_df = loading_the_data(dir + '\\\\val')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83d379-3ac2-4254-b99f-2e8dd012ea24",
   "metadata": {},
   "source": [
    "## Menambahkan Label Kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31334b2-0562-4f1c-a36c-e5b3a0cb595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>High</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>High</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>High</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>High</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>High</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...   High        1237\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...   High         628\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...   High         718\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...   High         805\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...   High        1093\n",
       "...                                                  ...    ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...  Water           0\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...  Water           0\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...  Water           0\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...  Water           0\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...  Water           0\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_df = pd.read_csv(\"conversion_cnt.csv\")\n",
    "train_df = pd.merge(train_df, cnt_df[['filepaths', 'grid_code']], on='filepaths', how='left')\n",
    "train_df.rename(columns={'grid_code': 'labels_cnt'}, inplace=True)\n",
    "\n",
    "cnt_df = pd.read_csv(\"conversion_test_cnt.csv\")\n",
    "test_df = pd.merge(test_df, cnt_df[['filepaths', 'grid_code']], on='filepaths', how='left')\n",
    "test_df.rename(columns={'grid_code': 'labels_cnt'}, inplace=True)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79043a5-fc98-4ecc-9f50-cf777d5be320",
   "metadata": {},
   "source": [
    "## Encoding Label Kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31475d5-faac-4bfe-b0d9-360e209c23b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>5</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>5</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>5</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>5</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>5</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths  labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...       5        1237\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...       5         628\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...       5         718\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...       5         805\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...       5        1093\n",
       "...                                                  ...     ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...       0           0\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...       0           0\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...       0           0\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...       0           0\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...       0           0\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['Water', 'Non-burnable', 'Very_Low', 'Low', 'Moderate', 'High', 'Very_High']\n",
    "label_encoder = OrdinalEncoder(categories=[class_names])\n",
    "\n",
    "train_df['labels'] = label_encoder.fit_transform(train_df[['labels']])\n",
    "test_df['labels'] = label_encoder.transform(test_df[['labels']])\n",
    "\n",
    "train_df['labels'] = train_df['labels'].astype('int64')\n",
    "test_df['labels'] = test_df['labels'].astype('int64')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a22da-0d0f-49f7-9286-da57beab74c3",
   "metadata": {},
   "source": [
    "## Normalisasi Label Kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdcd4d9-f7c0-4552-9c47-6ce9a3b58b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cont_label(label):\n",
    "    if label <= 0:\n",
    "        return 0\n",
    "    elif label <= 61:\n",
    "        return label / 61\n",
    "    elif 61 < label <= 178:\n",
    "        return (label - 61) / (178 - 61) + 1\n",
    "    elif 178 < label <= 489:\n",
    "        return (label - 178) / (489 - 178) + 2\n",
    "    elif 489 < label <= 1985:\n",
    "        return (label - 489) / (1985 - 489) + 3\n",
    "    elif 1985 < label:\n",
    "        return (label - 1985) / (100000 - 1985) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eed40f7-843f-4128-b03f-060ded6ad2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths  labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...       5       3.500\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...       5       3.093\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...       5       3.153\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...       5       3.211\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...       5       3.404\n",
       "...                                                  ...     ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...       0       0.000\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...       0       0.000\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...       0       0.000\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...       0       0.000\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...       0       0.000\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['labels_cnt'] = train_df['labels_cnt'].apply(normalize_cont_label).round(3)\n",
    "test_df['labels_cnt'] = test_df['labels_cnt'].apply(normalize_cont_label).round(3)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd2d128-0144-4591-bf5a-62067d32adf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70331.000000</td>\n",
       "      <td>70331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.547156</td>\n",
       "      <td>1.109816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.498586</td>\n",
       "      <td>1.271991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.576000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             labels    labels_cnt\n",
       "count  70331.000000  70331.000000\n",
       "mean       2.547156      1.109816\n",
       "std        1.498586      1.271991\n",
       "min        0.000000      0.000000\n",
       "25%        1.000000      0.000000\n",
       "50%        2.000000      0.557000\n",
       "75%        4.000000      2.035000\n",
       "max        6.000000      4.576000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc24c90-8701-4e94-a853-189e857d28d1",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c9018c-77f6-4d89-967a-65c8490f8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size = 0.2, shuffle = True, random_state = 49, stratify=train_df['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fcf20-08c4-4d02-936f-c3710e7d2442",
   "metadata": {},
   "source": [
    "## Augmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7afc818-0ce1-4082-93ad-08c68ac33840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRiskDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the file path and label for the index\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "        label_cnt = self.dataframe.iloc[idx, 2]\n",
    "        \n",
    "        # Open the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # If there is any transform (e.g., normalization, augmentation), apply it\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, label_cnt, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361f901e-2620-4b6f-b812-0496877f25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    # transforms.CenterCrop(224),  # Crop image to get 224x224 in the center\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    # transforms.RandomHorizontalFlip(p=0.2),  # Randomly flip image horizontally\n",
    "    # transforms.RandomAffine(degrees=10, translate=(0.03125, 0.03125), fill=(0, 0, 0)),  # Random affine transformations (rotation, translation)\n",
    "    # transforms.CenterCrop(224),  # Crop image to get 224x224 in the center\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = FireRiskDataset(dataframe=train_df, transform=augment)\n",
    "valid_dataset = FireRiskDataset(dataframe=valid_df, transform=transform)\n",
    "test_dataset = FireRiskDataset(dataframe=test_df, transform=transform)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a073ee-dd4e-42c4-b254-ba2b1a2349a6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e4d061-ce5b-479f-8e91-aa48d555426a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in globals() and model != None:\n",
    "    model.cpu()\n",
    "    del model\n",
    "if 'mae_model' in globals() and mae_model != None:\n",
    "    mae_model.cpu()\n",
    "    del mae_model\n",
    "if 'full_model' in globals() and full_model != None:\n",
    "    full_model.cpu()\n",
    "    del full_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e88fa0-61ea-4303-9aad-7e138389e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07a0cc-f136-45d4-9b0a-bb7386d1951f",
   "metadata": {},
   "source": [
    "## MAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aabd681d-dbf1-48df-812c-da0cd017d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAE model\n",
    "mae_model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "checkpoint = torch.load('mae_pretrain_vit_base.pth', weights_only=True)\n",
    "state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "mae_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Remove the final classification head (to use only the encoder part)\n",
    "mae_model.reset_classifier(0)\n",
    "mae_model = mae_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4763b4e-84d8-4199-ab08-47b55701bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters in the encoder\n",
    "for param in mae_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ab043a-6dde-44f8-a0f5-85fd7f4ec5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VisionTransformer                        [16, 768]                 152,064\n",
       "├─PatchEmbed: 1-1                        [16, 196, 768]            --\n",
       "│    └─Conv2d: 2-1                       [16, 768, 14, 14]         (590,592)\n",
       "│    └─Identity: 2-2                     [16, 196, 768]            --\n",
       "├─Dropout: 1-2                           [16, 197, 768]            --\n",
       "├─Identity: 1-3                          [16, 197, 768]            --\n",
       "├─Identity: 1-4                          [16, 197, 768]            --\n",
       "├─Sequential: 1-5                        [16, 197, 768]            --\n",
       "│    └─Block: 2-3                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-1               [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-2               [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-3                [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-4                [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-5               [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-6                     [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-7                [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-8                [16, 197, 768]            --\n",
       "│    └─Block: 2-4                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-9               [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-10              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-11               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-12               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-13              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-14                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-15               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-16               [16, 197, 768]            --\n",
       "│    └─Block: 2-5                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-17              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-18              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-19               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-20               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-21              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-22                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-23               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-24               [16, 197, 768]            --\n",
       "│    └─Block: 2-6                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-25              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-26              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-27               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-28               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-29              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-30                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-31               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-32               [16, 197, 768]            --\n",
       "│    └─Block: 2-7                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-33              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-34              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-35               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-36               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-37              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-38                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-39               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-40               [16, 197, 768]            --\n",
       "│    └─Block: 2-8                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-41              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-42              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-43               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-44               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-45              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-46                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-47               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-48               [16, 197, 768]            --\n",
       "│    └─Block: 2-9                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-49              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-50              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-51               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-52               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-53              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-54                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-55               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-56               [16, 197, 768]            --\n",
       "│    └─Block: 2-10                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-57              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-58              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-59               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-60               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-61              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-62                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-63               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-64               [16, 197, 768]            --\n",
       "│    └─Block: 2-11                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-65              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-66              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-67               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-68               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-69              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-70                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-71               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-72               [16, 197, 768]            --\n",
       "│    └─Block: 2-12                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-73              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-74              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-75               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-76               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-77              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-78                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-79               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-80               [16, 197, 768]            --\n",
       "│    └─Block: 2-13                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-81              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-82              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-83               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-84               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-85              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-86                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-87               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-88               [16, 197, 768]            --\n",
       "│    └─Block: 2-14                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-89              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-90              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-91               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-92               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-93              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-94                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-95               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-96               [16, 197, 768]            --\n",
       "├─LayerNorm: 1-6                         [16, 197, 768]            (1,536)\n",
       "├─Identity: 1-7                          [16, 768]                 --\n",
       "├─Dropout: 1-8                           [16, 768]                 --\n",
       "├─Identity: 1-9                          [16, 768]                 --\n",
       "==========================================================================================\n",
       "Total params: 85,798,656\n",
       "Trainable params: 0\n",
       "Non-trainable params: 85,798,656\n",
       "Total mult-adds (G): 3.21\n",
       "==========================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2594.93\n",
       "Params size (MB): 342.59\n",
       "Estimated Total Size (MB): 2947.15\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mae_model, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f3c5b-dcf4-4755-b800-9198870b623d",
   "metadata": {},
   "source": [
    "### Latent Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86dafcd7-7d6c-4548-8e53-aeb2899b0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_representations(dataloader, model, device):\n",
    "    model.eval()\n",
    "    latent_representations = []\n",
    "    labels = []\n",
    "    labels_cnt = []\n",
    "    filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets, targets_cnt, filename in tqdm(dataloader, unit=\"batch\"):\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass through the MAE encoder\n",
    "            latent = model(images)\n",
    "\n",
    "            latent_representations.append(latent.cpu())\n",
    "            labels.extend(targets)\n",
    "            labels_cnt.extend(targets_cnt)\n",
    "            filenames.extend(filename)\n",
    "\n",
    "    # Concatenate the results across batches\n",
    "    latent_representations = torch.cat(latent_representations, dim=0)\n",
    "\n",
    "    return latent_representations, labels, labels_cnt, filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e1136-1e10-46e8-a901-8bfa49d4d9b8",
   "metadata": {},
   "source": [
    "## Head Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "703d4a06-456e-4462-ab69-cc9f0798259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRisk_Head(nn.Module):\n",
    "    def __init__(self, num_classes=7, dropout_prob=0.5, latent_dim=768):\n",
    "        super(FireRisk_Head, self).__init__()\n",
    "\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Shared layers\n",
    "        self.shared = nn.Module()\n",
    "        \n",
    "        # From latent representation to 512 neurons\n",
    "        self.shared.fc1 = nn.Linear(768, 512)\n",
    "        self.shared.bn1 = nn.BatchNorm1d(512)\n",
    "        self.shared.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # # From 512 neurons to 256 neurons\n",
    "        # self.shared.fc2 = nn.Linear(512, 256)\n",
    "        # self.shared.bn2 = nn.BatchNorm1d(256)\n",
    "        # self.shared.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # Classification module\n",
    "        self.classification = nn.Module()\n",
    "        self.classification.fc1 = nn.Linear(512, 128)\n",
    "        self.classification.bn1 = nn.BatchNorm1d(128)\n",
    "        self.classification.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.classification.head = nn.Linear(128, num_classes)\n",
    "\n",
    "        # Regression module\n",
    "        self.regression = nn.Module()\n",
    "        self.regression.fc1 = nn.Linear(512, 128)\n",
    "        self.regression.bn1 = nn.BatchNorm1d(128)\n",
    "        self.regression.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.regression.head = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Fully connected layer (512 neurons)\n",
    "        x = self.shared.fc1(x)\n",
    "        x = self.shared.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.shared.dropout1(x)\n",
    "\n",
    "        # # Fully connected layer (256 neurons)\n",
    "        # x = self.shared.fc2(x)\n",
    "        # x = self.shared.bn2(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.shared.dropout2(x)\n",
    "\n",
    "        # Classification head (7 classes)\n",
    "        cls = self.classification.fc1(x)\n",
    "        cls = self.classification.bn1(cls)\n",
    "        cls = torch.relu(cls)\n",
    "        cls = self.classification.dropout1(cls)\n",
    "        cls = self.classification.head(cls)\n",
    "\n",
    "        # Regression head (1 continuous)\n",
    "        reg = self.regression.fc1(x)\n",
    "        reg = self.regression.bn1(reg)\n",
    "        reg = torch.relu(reg)\n",
    "        reg = self.regression.dropout1(reg)\n",
    "        reg = self.regression.head(reg)\n",
    "        \n",
    "        return cls, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6582b012-80d9-479e-bba8-e3cc4d113e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FireRisk_Head                            [16, 7]                   --\n",
       "├─Module: 1-1                            --                        --\n",
       "│    └─Linear: 2-1                       [16, 512]                 393,728\n",
       "│    └─BatchNorm1d: 2-2                  [16, 512]                 1,024\n",
       "│    └─Dropout: 2-3                      [16, 512]                 --\n",
       "├─Module: 1-2                            --                        --\n",
       "│    └─Linear: 2-4                       [16, 128]                 65,664\n",
       "│    └─BatchNorm1d: 2-5                  [16, 128]                 256\n",
       "│    └─Dropout: 2-6                      [16, 128]                 --\n",
       "│    └─Linear: 2-7                       [16, 7]                   903\n",
       "├─Module: 1-3                            --                        --\n",
       "│    └─Linear: 2-8                       [16, 128]                 65,664\n",
       "│    └─BatchNorm1d: 2-9                  [16, 128]                 256\n",
       "│    └─Dropout: 2-10                     [16, 128]                 --\n",
       "│    └─Linear: 2-11                      [16, 1]                   129\n",
       "==========================================================================================\n",
       "Total params: 527,624\n",
       "Trainable params: 527,624\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 8.44\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.20\n",
       "Params size (MB): 2.11\n",
       "Estimated Total Size (MB): 2.36\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "summary(model, input_size=(batch_size, 768))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75d65a-76ba-4fc5-af2b-f033b1540689",
   "metadata": {},
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02fe5a24-1a05-4e93-85ef-3b7dd533ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRisk_Full(nn.Module):\n",
    "    def __init__(self, mae_model, head_model, num_classes=7, dropout_prob=0.5):\n",
    "        super(FireRisk_Full, self).__init__()\n",
    "        \n",
    "        # MAE encoder\n",
    "        self.mae_encoder = mae_model\n",
    "        \n",
    "        # Prediction head\n",
    "        self.head = head_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the MAE encoder to get the latent representation\n",
    "        x = self.mae_encoder(x)\n",
    "\n",
    "        # Prediction head\n",
    "        cls, reg = self.head(x)\n",
    "        \n",
    "        return cls, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef030340-6592-4f5d-bbef-42df62f5dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "FireRisk_Full                                 [16, 7]                   --\n",
       "├─VisionTransformer: 1-1                      [16, 768]                 152,064\n",
       "│    └─PatchEmbed: 2-1                        [16, 196, 768]            --\n",
       "│    │    └─Conv2d: 3-1                       [16, 768, 14, 14]         (590,592)\n",
       "│    │    └─Identity: 3-2                     [16, 196, 768]            --\n",
       "│    └─Dropout: 2-2                           [16, 197, 768]            --\n",
       "│    └─Identity: 2-3                          [16, 197, 768]            --\n",
       "│    └─Identity: 2-4                          [16, 197, 768]            --\n",
       "│    └─Sequential: 2-5                        [16, 197, 768]            --\n",
       "│    │    └─Block: 3-3                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-4                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-5                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-6                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-7                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-8                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-9                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-10                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-11                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-12                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-13                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-14                       [16, 197, 768]            (7,087,872)\n",
       "│    └─LayerNorm: 2-6                         [16, 197, 768]            (1,536)\n",
       "│    └─Identity: 2-7                          [16, 768]                 --\n",
       "│    └─Dropout: 2-8                           [16, 768]                 --\n",
       "│    └─Identity: 2-9                          [16, 768]                 --\n",
       "├─FireRisk_Head: 1-2                          [16, 7]                   --\n",
       "│    └─Module: 2-10                           --                        --\n",
       "│    │    └─Linear: 3-15                      [16, 512]                 393,728\n",
       "│    │    └─BatchNorm1d: 3-16                 [16, 512]                 1,024\n",
       "│    │    └─Dropout: 3-17                     [16, 512]                 --\n",
       "│    └─Module: 2-11                           --                        --\n",
       "│    │    └─Linear: 3-18                      [16, 128]                 65,664\n",
       "│    │    └─BatchNorm1d: 3-19                 [16, 128]                 256\n",
       "│    │    └─Dropout: 3-20                     [16, 128]                 --\n",
       "│    │    └─Linear: 3-21                      [16, 7]                   903\n",
       "│    └─Module: 2-12                           --                        --\n",
       "│    │    └─Linear: 3-22                      [16, 128]                 65,664\n",
       "│    │    └─BatchNorm1d: 3-23                 [16, 128]                 256\n",
       "│    │    └─Dropout: 3-24                     [16, 128]                 --\n",
       "│    │    └─Linear: 3-25                      [16, 1]                   129\n",
       "===============================================================================================\n",
       "Total params: 86,326,280\n",
       "Trainable params: 527,624\n",
       "Non-trainable params: 85,798,656\n",
       "Total mult-adds (G): 3.22\n",
       "===============================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2595.13\n",
       "Params size (MB): 344.70\n",
       "Estimated Total Size (MB): 2949.46\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "full_model = FireRisk_Full(mae_model=mae_model, head_model=model, num_classes=7)\n",
    "summary(full_model, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e38645-65bc-40a6-be48-bfda687b0f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in globals() and model != None:\n",
    "    model.cpu()\n",
    "    del model\n",
    "if 'full_model' in globals() and full_model != None:\n",
    "    full_model.cpu()\n",
    "    del full_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db449093-d22d-4dd8-9935-75485ce035b2",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7c94440-518f-4a9b-bfa8-180a48bb64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentDataset(Dataset):\n",
    "    def __init__(self, latents, labels, labels_cnt, filenames):\n",
    "        self.latents = latents\n",
    "        # self.glcm = glcm\n",
    "        # self.lbp = lbp\n",
    "        self.labels = labels\n",
    "        self.labels_cnt = labels_cnt\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.latents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the latent and label for the index\n",
    "        latent = self.latents[idx]\n",
    "        # glcm_feat = self.glcm[idx]\n",
    "        # lbp_feat = self.lbp[idx]\n",
    "        label = self.labels[idx]\n",
    "        label_cnt = self.labels_cnt[idx]\n",
    "        filename = self.filenames[idx]\n",
    "\n",
    "        # combined = torch.cat([latent, glcm_feat, lbp_feat], dim=0).float()\n",
    "\n",
    "        return latent, label, label_cnt, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edae03-0cb2-4e6e-8fbd-c08d42d02abc",
   "metadata": {},
   "source": [
    "### Load latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0088483f-e8fc-42b2-afd8-9d996b1d2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed latent representations and labels\n",
    "train_data = torch.load('outputs/train_latents.pth', weights_only=True)\n",
    "valid_data = torch.load('outputs/valid_latents.pth', weights_only=True)\n",
    "\n",
    "# train_latents, train_glcm, train_lbp, train_labels, train_labels_cnt, train_filenames = train_data['latents'], train_data['glcm'], train_data['lbp'], train_data['labels'], train_data['labels_cnt'], train_data['filenames']\n",
    "# valid_latents, valid_glcm, valid_lbp, valid_labels, valid_labels_cnt, valid_filenames = valid_data['latents'], valid_data['glcm'], valid_data['lbp'], valid_data['labels'], valid_data['labels_cnt'], valid_data['filenames']\n",
    "train_latents, train_labels, train_labels_cnt, train_filenames = train_data['latents'], train_data['labels'], train_data['labels_cnt'], train_data['filenames']\n",
    "valid_latents, valid_labels, valid_labels_cnt, valid_filenames = valid_data['latents'], valid_data['labels'], valid_data['labels_cnt'], valid_data['filenames']\n",
    "\n",
    "# Min-max normalization\n",
    "min_val = np.min(train_labels_cnt)\n",
    "max_val = np.max(train_labels_cnt)\n",
    "train_labels_cnt_norm = (train_labels_cnt - min_val) / (max_val - min_val)\n",
    "valid_labels_cnt_norm = (valid_labels_cnt - min_val) / (max_val - min_val)\n",
    "\n",
    "# Create DataLoaders using the precomputed latents\n",
    "# train_lat_dataset = LatentDataset(train_latents[0], train_glcm[0], train_lbp[0], train_labels, train_labels_cnt_norm, train_filenames)\n",
    "# valid_lat_dataset = LatentDataset(valid_latents, valid_glcm, valid_lbp, valid_labels, valid_labels_cnt_norm, valid_filenames)\n",
    "train_lat_dataset = LatentDataset(train_latents, train_labels, train_labels_cnt_norm, train_filenames)\n",
    "valid_lat_dataset = LatentDataset(valid_latents, valid_labels, valid_labels_cnt_norm, valid_filenames)\n",
    "\n",
    "train_lat_loader = DataLoader(train_lat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_lat_loader = DataLoader(valid_lat_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051f285-0dd6-4b8c-a08b-c7de6fde3d58",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1591d119-a102-4450-9b19-2a45aa02ceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0): np.float64(2.9870853377876045),\n",
       " np.int64(1): np.float64(0.2879995261284951),\n",
       " np.int64(2): np.float64(0.23769682234046724),\n",
       " np.int64(3): np.float64(0.48302547493704984),\n",
       " np.int64(4): np.float64(0.6004518422112963),\n",
       " np.int64(5): np.float64(0.8216709419733529),\n",
       " np.int64(6): np.float64(1.582070054621733)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes, counts = np.unique(train_labels, return_counts=True)\n",
    "class_weights = {c: 1.0 / count for c, count in zip(classes, counts)}\n",
    "\n",
    "mean = sum(class_weights.values()) / len(class_weights)\n",
    "class_weights = {k: v / mean for k, v in class_weights.items()}\n",
    "\n",
    "weights_list = [class_weights[i] for i in range(len(classes))]\n",
    "weights_tensor = torch.tensor(weights_list, dtype=torch.float).to(device)\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a150b-a430-4687-85bc-238ef9537c3e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f2f4262-3221-4978-8f7a-ae56409e5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "start_lr = 0.0001\n",
    "min_lr = 0.000001\n",
    "max_lr = 0.001\n",
    "warmup_epochs = 9\n",
    "sustain_epochs = 0\n",
    "factor = 0.96\n",
    "epochs = 50\n",
    "\n",
    "weight = {\n",
    "    'cls': 1.0,\n",
    "    'reg': 0.2,\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "criterion_reg = nn.MSELoss(reduction='none')  # Mean Squared Error loss for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=start_lr)\n",
    "\n",
    "# lr_scheduler = CustomDecayLR(optimizer, epochs, warmup_epochs, sustain_epochs, factor, start_lr=start_lr, min_lr=min_lr, max_lr=max_lr)\n",
    "# lr_scheduler = CustomPlateauLR(optimizer, epochs, warmup_epochs, sustain_epochs, factor, patience=2, start_lr=start_lr, min_lr=min_lr, max_lr=max_lr)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, eta_min=min_lr)\n",
    "# early_stopping = EarlyStopping(patience=20, min_delta=0.0001, delta_metric='val_loss', start_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730498e-a830-4c45-b746-ef522b6d8b74",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8421095-cfe3-47ff-96f8-779a697be3c0",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2809e24-ad8e-4a1f-862d-e8b5d8778637",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3fae579e-a466-4f31-a314-cdaa787b6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed latent representations and labels\n",
    "test_data = torch.load('outputs/test_latents.pth', weights_only=True)\n",
    "# test_latents, test_glcm, test_lbp, test_labels, test_labels_cnt, test_filenames = test_data['latents'], test_data['glcm'], test_data['lbp'], test_data['labels'], test_data['labels_cnt'], test_data['filenames']\n",
    "test_latents, test_labels, test_labels_cnt, test_filenames = test_data['latents'], test_data['labels'], test_data['labels_cnt'], test_data['filenames']\n",
    "\n",
    "# Min-max normalization\n",
    "test_labels_cnt_norm = (test_labels_cnt - min_val) / (max_val - min_val)\n",
    "\n",
    "# Create DataLoaders using the precomputed latents\n",
    "# test_lat_dataset = LatentDataset(test_latents, test_glcm, test_lbp, test_labels, test_labels_cnt_norm, test_filenames)\n",
    "test_lat_dataset = LatentDataset(test_latents, test_labels, test_labels_cnt_norm, test_filenames)\n",
    "test_lat_loader = DataLoader(test_lat_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "366bba86-c2dc-4011-9962-a2205876c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_956\\1826315294.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('models/02/model_epoch_40.pth')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the FireRisk_Head model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "checkpoint = torch.load('models/02/model_epoch_40.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "\n",
    "# # Initialize the combined model with the MAE encoder and FireRisk_Head weights\n",
    "# full_model = FireRisk_Full(mae_model=mae_model, head_model=model, num_classes=7)\n",
    "# full_model = full_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8f1243df-5abe-4705-90c4-5bdea63adb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion_cls, criterion_reg, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_loss_reg = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_reg_preds = []\n",
    "    all_reg_labels = []\n",
    "    all_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "            for images, targets, target_reg, filenames in tepoch:\n",
    "                images, targets, targets_reg = images.to(device), targets.to(device), target_reg.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs_cls, outputs_reg = model(images)\n",
    "\n",
    "                # Calculate loss\n",
    "                targets_reg = targets_reg.to(torch.float).unsqueeze(1)\n",
    "                mask_reg = targets_reg != 0\n",
    "                \n",
    "                if mask_reg.any():\n",
    "                    loss_reg = criterion_reg(outputs_reg[mask_reg], targets_reg[mask_reg])\n",
    "                else:\n",
    "                    loss_reg = torch.tensor(0.0, device=device)\n",
    "                    \n",
    "                loss_cls = criterion_cls(outputs_cls, targets)\n",
    "\n",
    "                running_loss += loss_cls.item()\n",
    "                running_loss_reg += loss_reg.mean().item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs_cls, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(targets.cpu().numpy())\n",
    "                # Save regression outputs and labels\n",
    "                all_reg_preds.extend(outputs_reg.squeeze(1).cpu().numpy())\n",
    "                all_reg_labels.extend(targets_reg.squeeze(1).cpu().numpy())\n",
    "                all_filenames.extend(filenames)\n",
    "\n",
    "                # Update the tqdm progress bar\n",
    "                tepoch.set_postfix(loss=loss_cls.item(), accuracy=100 * correct / total)\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    avg_loss_reg = running_loss_reg / len(data_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, avg_loss_reg, accuracy, all_preds, all_labels, all_reg_preds, all_reg_labels, all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38afe3b8-ecc5-4c97-b1c5-6a415c8d3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_956\\2348026881.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_files[i])\n",
      "100%|███████████████████████████████████████████████| 1347/1347 [00:10<00:00, 133.46batch/s, accuracy=61.1, loss=0.668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, Test Loss: 1.0366, Test Loss Reg: 0.0372, Test Accuracy: 61.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:09<00:00, 137.28batch/s, accuracy=62.4, loss=0.573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2, Test Loss: 1.0150, Test Loss Reg: 0.0355, Test Accuracy: 62.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:09<00:00, 136.92batch/s, accuracy=62.7, loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3, Test Loss: 0.9865, Test Loss Reg: 0.0344, Test Accuracy: 62.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1347/1347 [00:10<00:00, 129.36batch/s, accuracy=61, loss=0.862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4, Test Loss: 1.0858, Test Loss Reg: 0.0374, Test Accuracy: 61.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 1347/1347 [00:10<00:00, 129.52batch/s, accuracy=62.1, loss=0.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5, Test Loss: 1.0123, Test Loss Reg: 0.0354, Test Accuracy: 62.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:10<00:00, 130.81batch/s, accuracy=62.7, loss=0.305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6, Test Loss: 0.9964, Test Loss Reg: 0.0328, Test Accuracy: 62.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1347/1347 [00:10<00:00, 129.84batch/s, accuracy=61, loss=0.603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7, Test Loss: 1.0829, Test Loss Reg: 0.0392, Test Accuracy: 61.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:10<00:00, 129.62batch/s, accuracy=62.2, loss=0.325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8, Test Loss: 0.9992, Test Loss Reg: 0.0352, Test Accuracy: 62.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:10<00:00, 130.33batch/s, accuracy=62.8, loss=0.236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9, Test Loss: 0.9769, Test Loss Reg: 0.0344, Test Accuracy: 62.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test dataset\n",
    "all_test_loss = []\n",
    "all_test_loss_reg = []\n",
    "all_test_accuracy = []\n",
    "all_test_preds = []\n",
    "all_test_labels = []\n",
    "all_test_reg_preds = []\n",
    "all_test_reg_labels = []\n",
    "all_test_filenames = []\n",
    "\n",
    "model_files = [\n",
    "    \"models/02/model_epoch_40.pth\",\n",
    "    \"models/02/model_epoch_60.pth\",\n",
    "    \"models/02/model_epoch_53.pth\",\n",
    "    \"models/05/model_epoch_136.pth\",\n",
    "    \"models/05/model_epoch_125.pth\",\n",
    "    \"models/05/model_epoch_147.pth\",\n",
    "    \"models/10/model_epoch_44.pth\",\n",
    "    \"models/10/model_epoch_63.pth\",\n",
    "    \"models/10/model_epoch_59.pth\"\n",
    "]\n",
    "\n",
    "for i in range(len(model_files)):\n",
    "    checkpoint = torch.load(model_files[i])\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    test_loss, test_loss_reg, test_accuracy, test_preds, test_labels, test_reg_preds, test_reg_labels, test_filenames = evaluate(model, test_lat_loader, criterion_cls, criterion_reg, device)\n",
    "    all_test_loss.append(test_loss)\n",
    "    all_test_loss_reg.append(test_loss_reg)\n",
    "    all_test_accuracy.append(test_accuracy)\n",
    "    all_test_preds.append(test_preds)\n",
    "    all_test_labels.append(test_labels)\n",
    "    all_test_reg_preds.append(test_reg_preds)\n",
    "    all_test_reg_labels.append(test_reg_labels)\n",
    "    all_test_filenames.append(test_filenames)\n",
    "    print(f\"Model {i+1}, Test Loss: {test_loss:.4f}, Test Loss Reg: {test_loss_reg:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c675e5-97fa-46a0-8828-637dd58cfb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses and Accuracies\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(all_test_loss, label='Loss')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Testing Loss')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(all_test_loss_reg, label='Reg Loss')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Reg Loss')\n",
    "plt.legend()\n",
    "plt.title('Testing Reg Loss')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(all_test_accuracy, label='Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Testing Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a0f7e66d-80f1-4b3c-a09b-65264eb0e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Metrics:\n",
      "  MAE:  0.1791\n",
      "  RMSE: 0.2255\n",
      "  R²:   0.4477\n",
      "Model 2 Metrics:\n",
      "  MAE:  0.1657\n",
      "  RMSE: 0.2207\n",
      "  R²:   0.4709\n",
      "Model 3 Metrics:\n",
      "  MAE:  0.1598\n",
      "  RMSE: 0.2175\n",
      "  R²:   0.4862\n",
      "Model 4 Metrics:\n",
      "  MAE:  0.1720\n",
      "  RMSE: 0.2266\n",
      "  R²:   0.4419\n",
      "Model 5 Metrics:\n",
      "  MAE:  0.1658\n",
      "  RMSE: 0.2202\n",
      "  R²:   0.4730\n",
      "Model 6 Metrics:\n",
      "  MAE:  0.1568\n",
      "  RMSE: 0.2120\n",
      "  R²:   0.5118\n",
      "Model 7 Metrics:\n",
      "  MAE:  0.1734\n",
      "  RMSE: 0.2319\n",
      "  R²:   0.4155\n",
      "Model 8 Metrics:\n",
      "  MAE:  0.1681\n",
      "  RMSE: 0.2196\n",
      "  R²:   0.4759\n",
      "Model 9 Metrics:\n",
      "  MAE:  0.1653\n",
      "  RMSE: 0.2172\n",
      "  R²:   0.4875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "all_test_mae = []\n",
    "all_test_rmse = []\n",
    "all_test_r2 = []\n",
    "\n",
    "for i in range(len(model_files)):\n",
    "    preds = np.array(all_test_reg_preds[i])\n",
    "    targets = np.array(all_test_reg_labels[i])\n",
    "\n",
    "    # Mask out targets == 0\n",
    "    mask = targets != 0\n",
    "    preds = preds[mask]\n",
    "    targets = targets[mask]\n",
    "\n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    rmse = mean_squared_error(targets, preds) ** 0.5\n",
    "    r2 = r2_score(targets, preds)\n",
    "\n",
    "    # Save\n",
    "    all_test_mae.append(mae)\n",
    "    all_test_rmse.append(rmse)\n",
    "    all_test_r2.append(r2)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Model {i+1} Metrics:\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15fd53-7060-429c-875d-ca835f5899bb",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2f511-3923-4f79-b091-dae16392f383",
   "metadata": {},
   "source": [
    "### Save session results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "048e83ca-3ac9-4a6e-9516-f9d3068bde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame({\n",
    "    'Filename': test_filenames,\n",
    "    'Label': test_labels,\n",
    "    'Prediction': test_preds\n",
    "})\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "test_results.to_csv('outputs/test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebfe369e-17b2-4887-84fd-6990f4970d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv('outputs/history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3afda9b-8a67-4d36-97f6-971a9dc394b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_results = pd.DataFrame({\n",
    "    'all_test_loss': all_test_loss,\n",
    "    'all_test_loss_reg': all_test_loss_reg,\n",
    "    'all_test_accuracy': all_test_accuracy\n",
    "})\n",
    "all_test_results.to_csv('outputs/all_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e8029-a314-42d7-983e-da09ef5118e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
