{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4173c20e-19af-4b0c-ae90-acffa873adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f8697f-dd0e-45ad-b441-06259fcccfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('outputs/run', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7fa16-8867-4f7b-a0a5-fea09a0cd05f",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e759250-6143-44e5-91e8-18ab147380fc",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b29ccbb-bfff-455d-9363-c843f2e0240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_the_data(data_dir):\n",
    "    # Generate data paths with labels\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    # Get folder names\n",
    "    folds = os.listdir(data_dir)\n",
    "\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(data_dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            \n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Concatenate data paths with labels into one DataFrame\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3055c21-3c9b-42dc-9fba-6154c973c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths labels\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...   High\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...   High\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...   High\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...   High\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...   High\n",
       "...                                                  ...    ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...  Water\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...  Water\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...  Water\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...  Water\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...  Water\n",
       "\n",
       "[70331 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = 'FireRisk'\n",
    "\n",
    "train_df = loading_the_data(dir + '\\\\train')\n",
    "test_df = loading_the_data(dir + '\\\\val')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83d379-3ac2-4254-b99f-2e8dd012ea24",
   "metadata": {},
   "source": [
    "## Menambahkan Label Kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31334b2-0562-4f1c-a36c-e5b3a0cb595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>High</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>High</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>High</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>High</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>High</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...   High        1237\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...   High         628\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...   High         718\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...   High         805\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...   High        1093\n",
       "...                                                  ...    ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...  Water           0\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...  Water           0\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...  Water           0\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...  Water           0\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...  Water           0\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_df = pd.read_csv(\"conversion_cnt.csv\")\n",
    "train_df = pd.merge(train_df, cnt_df[['filepaths', 'grid_code']], on='filepaths', how='left')\n",
    "train_df.rename(columns={'grid_code': 'labels_cnt'}, inplace=True)\n",
    "\n",
    "cnt_df = pd.read_csv(\"conversion_test_cnt.csv\")\n",
    "test_df = pd.merge(test_df, cnt_df[['filepaths', 'grid_code']], on='filepaths', how='left')\n",
    "test_df.rename(columns={'grid_code': 'labels_cnt'}, inplace=True)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79043a5-fc98-4ecc-9f50-cf777d5be320",
   "metadata": {},
   "source": [
    "## Encoding Label Kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31475d5-faac-4bfe-b0d9-360e209c23b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>5</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>5</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>5</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>5</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>5</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths  labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...       5        1237\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...       5         628\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...       5         718\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...       5         805\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...       5        1093\n",
       "...                                                  ...     ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...       0           0\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...       0           0\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...       0           0\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...       0           0\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...       0           0\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['Water', 'Non-burnable', 'Very_Low', 'Low', 'Moderate', 'High', 'Very_High']\n",
    "label_encoder = OrdinalEncoder(categories=[class_names])\n",
    "\n",
    "train_df['labels'] = label_encoder.fit_transform(train_df[['labels']])\n",
    "test_df['labels'] = label_encoder.transform(test_df[['labels']])\n",
    "\n",
    "train_df['labels'] = train_df['labels'].astype('int64')\n",
    "test_df['labels'] = test_df['labels'].astype('int64')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a22da-0d0f-49f7-9286-da57beab74c3",
   "metadata": {},
   "source": [
    "## Normalisasi Label Kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdcd4d9-f7c0-4552-9c47-6ce9a3b58b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cont_label(label):\n",
    "    if label <= 0:\n",
    "        return 0\n",
    "    elif label <= 61:\n",
    "        return label / 61\n",
    "    elif 61 < label <= 178:\n",
    "        return (label - 61) / (178 - 61) + 1\n",
    "    elif 178 < label <= 489:\n",
    "        return (label - 178) / (489 - 178) + 2\n",
    "    elif 489 < label <= 1985:\n",
    "        return (label - 489) / (1985 - 489) + 3\n",
    "    elif 1985 < label:\n",
    "        return (label - 1985) / (100000 - 1985) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eed40f7-843f-4128-b03f-060ded6ad2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths  labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...       5       3.500\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...       5       3.093\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...       5       3.153\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...       5       3.211\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...       5       3.404\n",
       "...                                                  ...     ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...       0       0.000\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...       0       0.000\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...       0       0.000\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...       0       0.000\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...       0       0.000\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['labels_cnt'] = train_df['labels_cnt'].apply(normalize_cont_label).round(3)\n",
    "test_df['labels_cnt'] = test_df['labels_cnt'].apply(normalize_cont_label).round(3)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd2d128-0144-4591-bf5a-62067d32adf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70331.000000</td>\n",
       "      <td>70331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.547156</td>\n",
       "      <td>1.109816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.498586</td>\n",
       "      <td>1.271991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.576000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             labels    labels_cnt\n",
       "count  70331.000000  70331.000000\n",
       "mean       2.547156      1.109816\n",
       "std        1.498586      1.271991\n",
       "min        0.000000      0.000000\n",
       "25%        1.000000      0.000000\n",
       "50%        2.000000      0.557000\n",
       "75%        4.000000      2.035000\n",
       "max        6.000000      4.576000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc24c90-8701-4e94-a853-189e857d28d1",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13cfa12-7459-4dd3-a31c-b5111ec94678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unused = 0.98\n",
    "# train_df, unused_df = train_test_split(train_df, test_size = unused, shuffle = True, random_state = 49, stratify=train_df['labels'])\n",
    "# test_df, unused_df = train_test_split(test_df, test_size = unused, shuffle = True, random_state = 49, stratify=test_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c9018c-77f6-4d89-967a-65c8490f8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size = 0.2, shuffle = True, random_state = 49, stratify=train_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92859bcb-dbc1-48f4-a398-ff52969f501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_autopct(pct):\n",
    "#     total = sum(data_balance)\n",
    "#     val = int(round(pct*total/100.0))\n",
    "#     return \"{:.1f}%\\n({:d})\".format(pct, val)\n",
    "\n",
    "# data_balance = train_df.labels.value_counts()\n",
    "# data_distribution = [train_df.size, valid_df.size]\n",
    "\n",
    "# plt.pie(data_distribution, labels = ['train', 'valid'], autopct=custom_autopct, colors = [\"#57A6DE\",\"#5D57DE\",\"#577BDE\",\"#43CFE0\",\"#A0B1DE\"])\n",
    "# plt.title(\"Data distribution\")\n",
    "# plt.axis(\"equal\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fcf20-08c4-4d02-936f-c3710e7d2442",
   "metadata": {},
   "source": [
    "## Augmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7afc818-0ce1-4082-93ad-08c68ac33840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRiskDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the file path and label for the index\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "        label_cnt = self.dataframe.iloc[idx, 2]\n",
    "        \n",
    "        # Open the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # If there is any transform (e.g., normalization, augmentation), apply it\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, label_cnt, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "361f901e-2620-4b6f-b812-0496877f25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    # transforms.CenterCrop(224),  # Crop image to get 224x224 in the center\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.RandomHorizontalFlip(p=0.2),  # Randomly flip image horizontally\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.03125, 0.03125), fill=(0, 0, 0)),  # Random affine transformations (rotation, translation)\n",
    "    # transforms.CenterCrop(224),  # Crop image to get 224x224 in the center\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = FireRiskDataset(dataframe=train_df, transform=augment)\n",
    "valid_dataset = FireRiskDataset(dataframe=valid_df, transform=transform)\n",
    "test_dataset = FireRiskDataset(dataframe=test_df, transform=transform)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb1e8e8-a761-490f-ada4-8ae2307d6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(img):\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Convert CHW to HWC format\n",
    "#     plt.show()\n",
    "\n",
    "# # Get a batch of training data and displaying it\n",
    "# data_iter = iter(train_loader)\n",
    "# images, labels, labels_cnt, _ = next(data_iter)\n",
    "# imshow(torchvision.utils.make_grid(images[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a073ee-dd4e-42c4-b254-ba2b1a2349a6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e4d061-ce5b-479f-8e91-aa48d555426a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in globals() and model != None:\n",
    "    model.cpu()\n",
    "    del model\n",
    "if 'mae_model' in globals() and mae_model != None:\n",
    "    mae_model.cpu()\n",
    "    del mae_model\n",
    "if 'full_model' in globals() and full_model != None:\n",
    "    full_model.cpu()\n",
    "    del full_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e88fa0-61ea-4303-9aad-7e138389e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07a0cc-f136-45d4-9b0a-bb7386d1951f",
   "metadata": {},
   "source": [
    "## MAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aabd681d-dbf1-48df-812c-da0cd017d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAE model\n",
    "mae_model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "checkpoint = torch.load('mae_pretrain_vit_base.pth', weights_only=True)\n",
    "state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "mae_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Remove the final classification head (to use only the encoder part)\n",
    "mae_model.reset_classifier(0)\n",
    "mae_model = mae_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4763b4e-84d8-4199-ab08-47b55701bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters in the encoder\n",
    "for param in mae_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60ab043a-6dde-44f8-a0f5-85fd7f4ec5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VisionTransformer                        [16, 768]                 152,064\n",
       "├─PatchEmbed: 1-1                        [16, 196, 768]            --\n",
       "│    └─Conv2d: 2-1                       [16, 768, 14, 14]         (590,592)\n",
       "│    └─Identity: 2-2                     [16, 196, 768]            --\n",
       "├─Dropout: 1-2                           [16, 197, 768]            --\n",
       "├─Identity: 1-3                          [16, 197, 768]            --\n",
       "├─Identity: 1-4                          [16, 197, 768]            --\n",
       "├─Sequential: 1-5                        [16, 197, 768]            --\n",
       "│    └─Block: 2-3                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-1               [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-2               [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-3                [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-4                [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-5               [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-6                     [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-7                [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-8                [16, 197, 768]            --\n",
       "│    └─Block: 2-4                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-9               [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-10              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-11               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-12               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-13              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-14                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-15               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-16               [16, 197, 768]            --\n",
       "│    └─Block: 2-5                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-17              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-18              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-19               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-20               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-21              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-22                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-23               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-24               [16, 197, 768]            --\n",
       "│    └─Block: 2-6                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-25              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-26              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-27               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-28               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-29              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-30                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-31               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-32               [16, 197, 768]            --\n",
       "│    └─Block: 2-7                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-33              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-34              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-35               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-36               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-37              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-38                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-39               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-40               [16, 197, 768]            --\n",
       "│    └─Block: 2-8                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-41              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-42              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-43               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-44               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-45              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-46                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-47               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-48               [16, 197, 768]            --\n",
       "│    └─Block: 2-9                        [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-49              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-50              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-51               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-52               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-53              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-54                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-55               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-56               [16, 197, 768]            --\n",
       "│    └─Block: 2-10                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-57              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-58              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-59               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-60               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-61              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-62                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-63               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-64               [16, 197, 768]            --\n",
       "│    └─Block: 2-11                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-65              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-66              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-67               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-68               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-69              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-70                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-71               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-72               [16, 197, 768]            --\n",
       "│    └─Block: 2-12                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-73              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-74              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-75               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-76               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-77              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-78                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-79               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-80               [16, 197, 768]            --\n",
       "│    └─Block: 2-13                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-81              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-82              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-83               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-84               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-85              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-86                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-87               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-88               [16, 197, 768]            --\n",
       "│    └─Block: 2-14                       [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-89              [16, 197, 768]            (1,536)\n",
       "│    │    └─Attention: 3-90              [16, 197, 768]            (2,362,368)\n",
       "│    │    └─Identity: 3-91               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-92               [16, 197, 768]            --\n",
       "│    │    └─LayerNorm: 3-93              [16, 197, 768]            (1,536)\n",
       "│    │    └─Mlp: 3-94                    [16, 197, 768]            (4,722,432)\n",
       "│    │    └─Identity: 3-95               [16, 197, 768]            --\n",
       "│    │    └─Identity: 3-96               [16, 197, 768]            --\n",
       "├─LayerNorm: 1-6                         [16, 197, 768]            (1,536)\n",
       "├─Identity: 1-7                          [16, 768]                 --\n",
       "├─Dropout: 1-8                           [16, 768]                 --\n",
       "├─Identity: 1-9                          [16, 768]                 --\n",
       "==========================================================================================\n",
       "Total params: 85,798,656\n",
       "Trainable params: 0\n",
       "Non-trainable params: 85,798,656\n",
       "Total mult-adds (G): 3.21\n",
       "==========================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2594.93\n",
       "Params size (MB): 342.59\n",
       "Estimated Total Size (MB): 2947.15\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mae_model, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f3c5b-dcf4-4755-b800-9198870b623d",
   "metadata": {},
   "source": [
    "### Latent Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86dafcd7-7d6c-4548-8e53-aeb2899b0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_representations(dataloader, model, device, epoch=1):\n",
    "    model.eval()\n",
    "    latent_representations = []\n",
    "    multi_latents = []\n",
    "    labels = []\n",
    "    labels_cnt = []\n",
    "    filenames = []\n",
    "\n",
    "    glcm_features = []\n",
    "    multi_glcm = []\n",
    "    lbp_features = []\n",
    "    multi_lbp = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets, targets_cnt, filename in tqdm(dataloader, unit=\"batch\"):\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass through the MAE encoder\n",
    "            latent = model(images)\n",
    "            latent_representations.append(latent.cpu())\n",
    "\n",
    "            # Extract GLCM and LBP\n",
    "            for i in range(images.size(0)):\n",
    "                glcm_feat, lbp_feat = extract_texture_features(images[i])\n",
    "                glcm_features.append(glcm_feat)\n",
    "                lbp_features.append(lbp_feat)\n",
    "\n",
    "            labels.extend(targets)\n",
    "            labels_cnt.extend(targets_cnt)\n",
    "            filenames.extend(filename)\n",
    "\n",
    "    # Concatenate the results across batches\n",
    "    latent_representations = torch.cat(latent_representations, dim=0)\n",
    "    glcm_features = torch.tensor(glcm_features)\n",
    "    lbp_features = torch.tensor(lbp_features)\n",
    "    \n",
    "    if epoch == 1:\n",
    "        return latent_representations, glcm_features, lbp_features, labels, labels_cnt, filenames\n",
    "    \n",
    "    multi_latents.append(latent_representations)\n",
    "    multi_glcm.append(glcm_features)\n",
    "    multi_lbp.append(lbp_features)\n",
    "    \n",
    "    while epoch > 1:\n",
    "        latent_representations = []\n",
    "        glcm_features = []\n",
    "        lbp_features = []\n",
    "        with torch.no_grad():\n",
    "            for images, targets, targets_cnt, filename in tqdm(dataloader, unit=\"batch\"):\n",
    "                images = images.to(device)\n",
    "    \n",
    "                # Forward pass through the MAE encoder\n",
    "                latent = model(images)\n",
    "                latent_representations.append(latent.cpu())\n",
    "\n",
    "                # Extract GLCM and LBP\n",
    "                for i in range(images.size(0)):\n",
    "                    glcm_feat, lbp_feat = extract_texture_features(images[i])\n",
    "                    glcm_features.append(glcm_feat)\n",
    "                    lbp_features.append(lbp_feat)\n",
    "    \n",
    "        # Concatenate the results across batches\n",
    "        latent_representations = torch.cat(latent_representations, dim=0)\n",
    "        glcm_features = torch.tensor(glcm_features)\n",
    "        lbp_features = torch.tensor(lbp_features)\n",
    "        \n",
    "        multi_latents.append(latent_representations)\n",
    "        multi_glcm.append(glcm_features)\n",
    "        multi_lbp.append(lbp_features)\n",
    "        epoch -= 1\n",
    "\n",
    "    return multi_latents, multi_glcm, multi_lbp, labels, labels_cnt, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41935a0d-6842-40f8-9e31-9edb5cae0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract latent representations for the training and validation datasets\n",
    "# train_latents, train_glcm, train_lbp, train_labels, train_labels_cnt, train_filenames = extract_latent_representations(train_loader, mae_model, device, 50)\n",
    "# torch.save({'latents': train_latents, 'glcm': train_glcm, 'lbp': train_lbp, 'labels': train_labels, 'labels_cnt': train_labels_cnt, 'filenames': train_filenames}, 'outputs/train_latents.pth')\n",
    "\n",
    "# valid_latents, valid_glcm, valid_lbp, valid_labels, valid_labels_cnt, valid_filenames = extract_latent_representations(valid_loader, mae_model, device)\n",
    "# torch.save({'latents': valid_latents, 'glcm': valid_glcm, 'lbp': valid_lbp, 'labels': valid_labels, 'labels_cnt': valid_labels_cnt, 'filenames': valid_filenames}, 'outputs/valid_latents.pth')\n",
    "\n",
    "# test_latents, test_glcm, test_lbp, test_labels, test_labels_cnt, test_filenames = extract_latent_representations(test_loader, mae_model, device)\n",
    "# torch.save({'latents': test_latents, 'glcm': test_glcm, 'lbp': test_lbp, 'labels': test_labels, 'labels_cnt': test_labels_cnt, 'filenames': test_filenames}, 'outputs/test_latents.pth')\n",
    "\n",
    "# print(len(train_latents))\n",
    "# print(valid_latents.shape)\n",
    "# print(test_latents.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e1136-1e10-46e8-a901-8bfa49d4d9b8",
   "metadata": {},
   "source": [
    "## Head Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "703d4a06-456e-4462-ab69-cc9f0798259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRisk_Head(nn.Module):\n",
    "    def __init__(self, num_classes=7, dropout_prob=0.5):\n",
    "        super(FireRisk_Head, self).__init__()\n",
    "\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Shared layers\n",
    "        self.shared = nn.Module()\n",
    "        \n",
    "        # From latent representation to 512 neurons\n",
    "        self.shared.fc1 = nn.Linear(768, 512)\n",
    "        self.shared.bn1 = nn.BatchNorm1d(512)\n",
    "        self.shared.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # # From 512 neurons to 256 neurons\n",
    "        # self.shared.fc2 = nn.Linear(512, 256)\n",
    "        # self.shared.bn2 = nn.BatchNorm1d(256)\n",
    "        # self.shared.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # Classification module\n",
    "        self.classification = nn.Module()\n",
    "        self.classification.fc1 = nn.Linear(512, 128)\n",
    "        self.classification.bn1 = nn.BatchNorm1d(128)\n",
    "        self.classification.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.classification.head = nn.Linear(128, num_classes)\n",
    "\n",
    "        # Regression module\n",
    "        self.regression = nn.Module()\n",
    "        self.regression.fc1 = nn.Linear(512, 128)\n",
    "        self.regression.bn1 = nn.BatchNorm1d(128)\n",
    "        self.regression.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.regression.head = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Fully connected layer (512 neurons)\n",
    "        x = self.shared.fc1(x)\n",
    "        x = self.shared.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.shared.dropout1(x)\n",
    "\n",
    "        # # Fully connected layer (256 neurons)\n",
    "        # x = self.shared.fc2(x)\n",
    "        # x = self.shared.bn2(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.shared.dropout2(x)\n",
    "\n",
    "        # Classification head (7 classes)\n",
    "        cls = self.classification.fc1(x)\n",
    "        cls = self.classification.bn1(cls)\n",
    "        cls = torch.relu(cls)\n",
    "        cls = self.classification.dropout1(cls)\n",
    "        cls = self.classification.head(cls)\n",
    "\n",
    "        # Regression head (1 continuous)\n",
    "        reg = self.regression.fc1(x)\n",
    "        reg = self.regression.bn1(reg)\n",
    "        reg = torch.relu(reg)\n",
    "        reg = self.regression.dropout1(reg)\n",
    "        reg = self.regression.head(reg)\n",
    "        \n",
    "        return cls, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6582b012-80d9-479e-bba8-e3cc4d113e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FireRisk_Head                            [16, 7]                   --\n",
       "├─Module: 1-1                            --                        --\n",
       "│    └─Linear: 2-1                       [16, 512]                 393,728\n",
       "│    └─BatchNorm1d: 2-2                  [16, 512]                 1,024\n",
       "│    └─Dropout: 2-3                      [16, 512]                 --\n",
       "├─Module: 1-2                            --                        --\n",
       "│    └─Linear: 2-4                       [16, 128]                 65,664\n",
       "│    └─BatchNorm1d: 2-5                  [16, 128]                 256\n",
       "│    └─Dropout: 2-6                      [16, 128]                 --\n",
       "│    └─Linear: 2-7                       [16, 7]                   903\n",
       "├─Module: 1-3                            --                        --\n",
       "│    └─Linear: 2-8                       [16, 128]                 65,664\n",
       "│    └─BatchNorm1d: 2-9                  [16, 128]                 256\n",
       "│    └─Dropout: 2-10                     [16, 128]                 --\n",
       "│    └─Linear: 2-11                      [16, 1]                   129\n",
       "==========================================================================================\n",
       "Total params: 527,624\n",
       "Trainable params: 527,624\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 8.44\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.20\n",
       "Params size (MB): 2.11\n",
       "Estimated Total Size (MB): 2.36\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "summary(model, input_size=(batch_size, 768))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75d65a-76ba-4fc5-af2b-f033b1540689",
   "metadata": {},
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02fe5a24-1a05-4e93-85ef-3b7dd533ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRisk_Full(nn.Module):\n",
    "    def __init__(self, mae_model, head_model, num_classes=7, dropout_prob=0.5):\n",
    "        super(FireRisk_Full, self).__init__()\n",
    "        \n",
    "        # MAE encoder\n",
    "        self.mae_encoder = mae_model\n",
    "        \n",
    "        # Prediction head\n",
    "        self.head = head_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the MAE encoder to get the latent representation\n",
    "        x = self.mae_encoder(x)\n",
    "\n",
    "        # Prediction head\n",
    "        cls, reg = self.head(x)\n",
    "        \n",
    "        return cls, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef030340-6592-4f5d-bbef-42df62f5dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "FireRisk_Full                                 [16, 7]                   --\n",
       "├─VisionTransformer: 1-1                      [16, 768]                 152,064\n",
       "│    └─PatchEmbed: 2-1                        [16, 196, 768]            --\n",
       "│    │    └─Conv2d: 3-1                       [16, 768, 14, 14]         (590,592)\n",
       "│    │    └─Identity: 3-2                     [16, 196, 768]            --\n",
       "│    └─Dropout: 2-2                           [16, 197, 768]            --\n",
       "│    └─Identity: 2-3                          [16, 197, 768]            --\n",
       "│    └─Identity: 2-4                          [16, 197, 768]            --\n",
       "│    └─Sequential: 2-5                        [16, 197, 768]            --\n",
       "│    │    └─Block: 3-3                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-4                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-5                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-6                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-7                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-8                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-9                        [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-10                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-11                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-12                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-13                       [16, 197, 768]            (7,087,872)\n",
       "│    │    └─Block: 3-14                       [16, 197, 768]            (7,087,872)\n",
       "│    └─LayerNorm: 2-6                         [16, 197, 768]            (1,536)\n",
       "│    └─Identity: 2-7                          [16, 768]                 --\n",
       "│    └─Dropout: 2-8                           [16, 768]                 --\n",
       "│    └─Identity: 2-9                          [16, 768]                 --\n",
       "├─FireRisk_Head: 1-2                          [16, 7]                   --\n",
       "│    └─Module: 2-10                           --                        --\n",
       "│    │    └─Linear: 3-15                      [16, 512]                 393,728\n",
       "│    │    └─BatchNorm1d: 3-16                 [16, 512]                 1,024\n",
       "│    │    └─Dropout: 3-17                     [16, 512]                 --\n",
       "│    └─Module: 2-11                           --                        --\n",
       "│    │    └─Linear: 3-18                      [16, 128]                 65,664\n",
       "│    │    └─BatchNorm1d: 3-19                 [16, 128]                 256\n",
       "│    │    └─Dropout: 3-20                     [16, 128]                 --\n",
       "│    │    └─Linear: 3-21                      [16, 7]                   903\n",
       "│    └─Module: 2-12                           --                        --\n",
       "│    │    └─Linear: 3-22                      [16, 128]                 65,664\n",
       "│    │    └─BatchNorm1d: 3-23                 [16, 128]                 256\n",
       "│    │    └─Dropout: 3-24                     [16, 128]                 --\n",
       "│    │    └─Linear: 3-25                      [16, 1]                   129\n",
       "===============================================================================================\n",
       "Total params: 86,326,280\n",
       "Trainable params: 527,624\n",
       "Non-trainable params: 85,798,656\n",
       "Total mult-adds (G): 3.22\n",
       "===============================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2595.13\n",
       "Params size (MB): 344.70\n",
       "Estimated Total Size (MB): 2949.46\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "full_model = FireRisk_Full(mae_model=mae_model, head_model=model, num_classes=7)\n",
    "summary(full_model, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e38645-65bc-40a6-be48-bfda687b0f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in globals() and model != None:\n",
    "    model.cpu()\n",
    "    del model\n",
    "if 'full_model' in globals() and full_model != None:\n",
    "    full_model.cpu()\n",
    "    del full_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db449093-d22d-4dd8-9935-75485ce035b2",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189b240-dee3-43d8-a0a6-5e7098a1b50d",
   "metadata": {},
   "source": [
    "## Custom Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4efed8c1-1051-44bd-8d13-3267d3f5cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecayLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, total_epochs, warmup_epochs, sustain_epochs, factor, start_lr=0.000001, min_lr=0.000001, max_lr=0.001, last_epoch=-1):\n",
    "        self.total_epochs = total_epochs\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.sustain_epochs = sustain_epochs\n",
    "        self.factor = factor\n",
    "        self.start_lr = start_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        epoch = self.last_epoch\n",
    "        # Ramp-up phase\n",
    "        if epoch <= self.warmup_epochs:\n",
    "            lr = self.start_lr + (self.max_lr - self.start_lr) * (epoch / self.warmup_epochs)\n",
    "        # Sustain phase\n",
    "        elif epoch <= self.warmup_epochs + self.sustain_epochs:\n",
    "            lr = self.max_lr\n",
    "        # Decay phase\n",
    "        else:\n",
    "            lr = self.max_lr * self.factor ** (epoch - self.warmup_epochs - self.sustain_epochs)\n",
    "            lr = max(lr, self.min_lr)\n",
    "\n",
    "        return [lr] * len(self.base_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d67b5548-ecce-4537-85f1-6ef918cd4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPlateauLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, total_epochs, warmup_epochs, sustain_epochs, factor, patience, start_lr=0.000001, min_lr=0.000001, max_lr=0.001, last_epoch=-1):\n",
    "        self.total_epochs = total_epochs\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.sustain_epochs = sustain_epochs\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.start_lr = start_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.reduceLRFlag = False\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "        self.plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min',\n",
    "            factor=self.factor,\n",
    "            patience=self.patience,\n",
    "            min_lr=self.min_lr\n",
    "        )\n",
    "\n",
    "    def get_lr(self):\n",
    "        epoch = self.last_epoch\n",
    "        # Ramp-up phase\n",
    "        if epoch <= self.warmup_epochs:\n",
    "            lr = self.start_lr + (self.max_lr - self.start_lr) * (epoch / self.warmup_epochs)\n",
    "        # Sustain phase\n",
    "        elif epoch <= self.warmup_epochs + self.sustain_epochs:\n",
    "            lr = self.max_lr\n",
    "        # ReduceLROnPlateau\n",
    "        else:\n",
    "            self.reduceLRFlag = True\n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "        return [lr] * len(self.base_lrs)\n",
    "\n",
    "    def step(self, metric=None):\n",
    "        if self.reduceLRFlag:\n",
    "            self.plateau_scheduler.step(metric)\n",
    "        super().step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c744ab75-af19-4011-b3ee-4bf2131b2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, verbose=False, delta_metric='val_loss', start_epoch=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.delta_metric = delta_metric\n",
    "        self.best_metric = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.start_epoch = start_epoch\n",
    "        self.best_model_weights = None\n",
    "\n",
    "    def __call__(self, epoch, val_loss, val_accuracy):\n",
    "        current_metric = val_loss if self.delta_metric == 'val_loss' else val_accuracy\n",
    "\n",
    "        if epoch >= self.start_epoch:\n",
    "            if self.best_metric is None:\n",
    "                self.best_metric = current_metric\n",
    "                self.best_model_weights = model.state_dict()\n",
    "            elif current_metric < self.best_metric - self.min_delta:\n",
    "                self.best_metric = current_metric\n",
    "                self.best_model_weights = model.state_dict()\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "                    if self.verbose:\n",
    "                        print(f'Early stopping triggered! No improvement after {self.patience} epochs.')\n",
    "\n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7c94440-518f-4a9b-bfa8-180a48bb64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentDataset(Dataset):\n",
    "    def __init__(self, latents, labels, labels_cnt, filenames):\n",
    "        self.latents = latents\n",
    "        # self.glcm = glcm\n",
    "        # self.lbp = lbp\n",
    "        self.labels = labels\n",
    "        self.labels_cnt = labels_cnt\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.latents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the latent and label for the index\n",
    "        latent = self.latents[idx]\n",
    "        # glcm_feat = self.glcm[idx]\n",
    "        # lbp_feat = self.lbp[idx]\n",
    "        label = self.labels[idx]\n",
    "        label_cnt = self.labels_cnt[idx]\n",
    "        filename = self.filenames[idx]\n",
    "\n",
    "        # combined = torch.cat([latent, glcm_feat, lbp_feat], dim=0).float()\n",
    "\n",
    "        return latent, label, label_cnt, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edae03-0cb2-4e6e-8fbd-c08d42d02abc",
   "metadata": {},
   "source": [
    "### Load latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0088483f-e8fc-42b2-afd8-9d996b1d2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_7028\\3631476235.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load('outputs/train_latents.pth')\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_7028\\3631476235.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  valid_data = torch.load('outputs/valid_latents.pth')\n"
     ]
    }
   ],
   "source": [
    "# Load precomputed latent representations and labels\n",
    "train_data = torch.load('outputs/train_latents.pth', weights_only=True)\n",
    "valid_data = torch.load('outputs/valid_latents.pth', weights_only=True)\n",
    "\n",
    "# train_latents, train_glcm, train_lbp, train_labels, train_labels_cnt, train_filenames = train_data['latents'], train_data['glcm'], train_data['lbp'], train_data['labels'], train_data['labels_cnt'], train_data['filenames']\n",
    "# valid_latents, valid_glcm, valid_lbp, valid_labels, valid_labels_cnt, valid_filenames = valid_data['latents'], valid_data['glcm'], valid_data['lbp'], valid_data['labels'], valid_data['labels_cnt'], valid_data['filenames']\n",
    "train_latents, train_labels, train_labels_cnt, train_filenames = train_data['latents'], train_data['labels'], train_data['labels_cnt'], train_data['filenames']\n",
    "valid_latents, valid_labels, valid_labels_cnt, valid_filenames = valid_data['latents'], valid_data['labels'], valid_data['labels_cnt'], valid_data['filenames']\n",
    "\n",
    "# Min-max normalization\n",
    "min_val = np.min(train_labels_cnt)\n",
    "max_val = np.max(train_labels_cnt)\n",
    "train_labels_cnt_norm = (train_labels_cnt - min_val) / (max_val - min_val)\n",
    "valid_labels_cnt_norm = (valid_labels_cnt - min_val) / (max_val - min_val)\n",
    "\n",
    "# Create DataLoaders using the precomputed latents\n",
    "# train_lat_dataset = LatentDataset(train_latents[0], train_glcm[0], train_lbp[0], train_labels, train_labels_cnt_norm, train_filenames)\n",
    "# valid_lat_dataset = LatentDataset(valid_latents, valid_glcm, valid_lbp, valid_labels, valid_labels_cnt_norm, valid_filenames)\n",
    "train_lat_dataset = LatentDataset(train_latents, train_labels, train_labels_cnt_norm, train_filenames)\n",
    "valid_lat_dataset = LatentDataset(valid_latents, valid_labels, valid_labels_cnt_norm, valid_filenames)\n",
    "\n",
    "train_lat_loader = DataLoader(train_lat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_lat_loader = DataLoader(valid_lat_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a150b-a430-4687-85bc-238ef9537c3e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f2f4262-3221-4978-8f7a-ae56409e5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "start_lr = 0.0001\n",
    "min_lr = 0.000001\n",
    "max_lr = 0.001\n",
    "warmup_epochs = 9\n",
    "sustain_epochs = 0\n",
    "factor = 0.96\n",
    "epochs = 150\n",
    "\n",
    "weight = {\n",
    "    'cls': 1.0,\n",
    "    'reg': 0.2,\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "criterion_reg = nn.MSELoss(reduction='none')  # Mean Squared Error loss for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=start_lr)\n",
    "\n",
    "lr_scheduler = CustomDecayLR(optimizer, epochs, warmup_epochs, sustain_epochs, factor, start_lr=start_lr, min_lr=min_lr, max_lr=max_lr)\n",
    "# lr_scheduler = CustomPlateauLR(optimizer, epochs, warmup_epochs, sustain_epochs, factor, patience=2, start_lr=start_lr, min_lr=min_lr, max_lr=max_lr)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, eta_min=min_lr)\n",
    "# early_stopping = EarlyStopping(patience=20, min_delta=0.0001, delta_metric='val_loss', start_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fded83-bdef-4dbe-8a01-78263b5cdb8a",
   "metadata": {},
   "source": [
    "### Use all train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddbe1ed5-fc85-4419-9a61-5f248e779e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lat_dataset = ConcatDataset([train_lat_dataset, valid_lat_dataset])\n",
    "# train_lat_loader = DataLoader(train_lat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730498e-a830-4c45-b746-ef522b6d8b74",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea849ab9-1afe-44ea-bc00-7f450f27ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear checkpoints\n",
    "checkpoints_path = 'outputs/run'\n",
    "\n",
    "for filename in os.listdir(checkpoints_path):\n",
    "    file_path = os.path.join(checkpoints_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d11d58f2-cc3c-4c6a-af4c-e231b4d6efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 703/703 [00:05<00:00, 126.69batch/s, accuracy=43, loss=1.76]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 288.39batch/s, accuracy=51.2, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, loss: 1.5412, acc: 42.98%, val_loss: 1.2927, val_acc: 51.17%, lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 703/703 [00:05<00:00, 129.74batch/s, accuracy=49.1, loss=1.3]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 293.90batch/s, accuracy=52.6, val_loss=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, loss: 1.3120, acc: 49.10%, val_loss: 1.2059, val_acc: 52.56%, lr: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:06<00:00, 110.54batch/s, accuracy=50.4, loss=1.37]\n",
      "100%|███████████████████████████████████████████████| 176/176 [00:00<00:00, 279.61batch/s, accuracy=52.9, val_loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, loss: 1.2562, acc: 50.44%, val_loss: 1.1833, val_acc: 52.95%, lr: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 118.79batch/s, accuracy=52.5, loss=1.01]\n",
      "100%|███████████████████████████████████████████████| 176/176 [00:00<00:00, 265.53batch/s, accuracy=54.1, val_loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, loss: 1.2157, acc: 52.48%, val_loss: 1.1614, val_acc: 54.09%, lr: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:06<00:00, 112.73batch/s, accuracy=53.2, loss=0.648]\n",
      "100%|███████████████████████████████████████████████| 176/176 [00:00<00:00, 271.74batch/s, accuracy=53.9, val_loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, loss: 1.1979, acc: 53.17%, val_loss: 1.1628, val_acc: 53.91%, lr: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 121.03batch/s, accuracy=53.2, loss=1.42]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 301.56batch/s, accuracy=54.4, val_loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, loss: 1.1759, acc: 53.23%, val_loss: 1.1376, val_acc: 54.41%, lr: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 703/703 [00:06<00:00, 115.76batch/s, accuracy=53.3, loss=1.3]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 295.55batch/s, accuracy=54.1, val_loss=1.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, loss: 1.1807, acc: 53.29%, val_loss: 1.1573, val_acc: 54.05%, lr: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 124.06batch/s, accuracy=53.3, loss=1.26]\n",
      "100%|████████████████████████████████████████████████| 176/176 [00:00<00:00, 284.02batch/s, accuracy=55, val_loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, loss: 1.1749, acc: 53.30%, val_loss: 1.1267, val_acc: 55.05%, lr: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 703/703 [00:05<00:00, 117.79batch/s, accuracy=53.7, loss=1.3]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 285.46batch/s, accuracy=55.5, val_loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, loss: 1.1682, acc: 53.74%, val_loss: 1.1328, val_acc: 55.54%, lr: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:06<00:00, 115.10batch/s, accuracy=53.3, loss=1.16]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 284.95batch/s, accuracy=53.7, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, loss: 1.1632, acc: 53.25%, val_loss: 1.1361, val_acc: 53.70%, lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 117.51batch/s, accuracy=53.9, loss=1.54]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 267.76batch/s, accuracy=55.7, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, loss: 1.1404, acc: 53.87%, val_loss: 1.1217, val_acc: 55.65%, lr: 0.00096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:06<00:00, 111.52batch/s, accuracy=54.4, loss=1.02]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 278.30batch/s, accuracy=54.7, val_loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, loss: 1.1416, acc: 54.42%, val_loss: 1.1141, val_acc: 54.66%, lr: 0.0009216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 122.70batch/s, accuracy=55.3, loss=0.964]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 281.91batch/s, accuracy=56.4, val_loss=1.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, loss: 1.1229, acc: 55.25%, val_loss: 1.0983, val_acc: 56.43%, lr: 0.000884736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 127.13batch/s, accuracy=55.3, loss=0.907]\n",
      "100%|████████████████████████████████████████████████| 176/176 [00:00<00:00, 289.99batch/s, accuracy=55, val_loss=1.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, loss: 1.1166, acc: 55.30%, val_loss: 1.1167, val_acc: 54.98%, lr: 0.000849347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:06<00:00, 116.94batch/s, accuracy=55.6, loss=1.27]\n",
      "100%|███████████████████████████████████████████████| 176/176 [00:00<00:00, 287.82batch/s, accuracy=55.2, val_loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, loss: 1.1075, acc: 55.57%, val_loss: 1.1085, val_acc: 55.15%, lr: 0.000815373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 122.20batch/s, accuracy=55.8, loss=0.929]\n",
      "100%|████████████████████████████████████████████████| 176/176 [00:00<00:00, 275.56batch/s, accuracy=56, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, loss: 1.0960, acc: 55.77%, val_loss: 1.0877, val_acc: 55.97%, lr: 0.000782758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 126.20batch/s, accuracy=56.4, loss=0.864]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 326.14batch/s, accuracy=55.7, val_loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, loss: 1.0852, acc: 56.37%, val_loss: 1.1012, val_acc: 55.72%, lr: 0.000751447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 124.60batch/s, accuracy=56.4, loss=1.56]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 275.24batch/s, accuracy=56.3, val_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, loss: 1.0787, acc: 56.43%, val_loss: 1.0828, val_acc: 56.25%, lr: 0.00072139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 703/703 [00:05<00:00, 126.27batch/s, accuracy=57, loss=0.907]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 303.63batch/s, accuracy=56.8, val_loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, loss: 1.0743, acc: 56.97%, val_loss: 1.0844, val_acc: 56.79%, lr: 0.000692534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 703/703 [00:05<00:00, 126.43batch/s, accuracy=57, loss=1.07]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 308.00batch/s, accuracy=56.9, val_loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, loss: 1.0616, acc: 57.00%, val_loss: 1.0844, val_acc: 56.93%, lr: 0.000664833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 130.29batch/s, accuracy=57.3, loss=1.37]\n",
      "100%|████████████████████████████████████████████████| 176/176 [00:00<00:00, 306.43batch/s, accuracy=57, val_loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, loss: 1.0607, acc: 57.33%, val_loss: 1.0716, val_acc: 57.00%, lr: 0.000638239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 131.30batch/s, accuracy=58.1, loss=0.821]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 290.68batch/s, accuracy=57.5, val_loss=1.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, loss: 1.0477, acc: 58.08%, val_loss: 1.0758, val_acc: 57.46%, lr: 0.00061271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:06<00:00, 113.16batch/s, accuracy=57.9, loss=1.18]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 274.32batch/s, accuracy=56.8, val_loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, loss: 1.0426, acc: 57.93%, val_loss: 1.0755, val_acc: 56.79%, lr: 0.000588201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:06<00:00, 117.03batch/s, accuracy=57.7, loss=0.828]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 323.00batch/s, accuracy=57.7, val_loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, loss: 1.0331, acc: 57.67%, val_loss: 1.0685, val_acc: 57.68%, lr: 0.000564673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 127.44batch/s, accuracy=58.3, loss=0.74]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 313.53batch/s, accuracy=57.6, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, loss: 1.0311, acc: 58.29%, val_loss: 1.0706, val_acc: 57.60%, lr: 0.000542086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 703/703 [00:05<00:00, 128.41batch/s, accuracy=58.8, loss=1.3]\n",
      "100%|████████████████████████████████████████████████| 176/176 [00:00<00:00, 321.52batch/s, accuracy=56, val_loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, loss: 1.0221, acc: 58.76%, val_loss: 1.0730, val_acc: 56.01%, lr: 0.000520403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 120.18batch/s, accuracy=58.7, loss=1.33]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 317.74batch/s, accuracy=57.5, val_loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, loss: 1.0194, acc: 58.74%, val_loss: 1.0683, val_acc: 57.46%, lr: 0.000499587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 118.62batch/s, accuracy=59.1, loss=0.89]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 322.30batch/s, accuracy=57.1, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, loss: 1.0050, acc: 59.12%, val_loss: 1.0809, val_acc: 57.11%, lr: 0.000479603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 129.03batch/s, accuracy=59.4, loss=1.01]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 307.02batch/s, accuracy=57.1, val_loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, loss: 1.0069, acc: 59.43%, val_loss: 1.0689, val_acc: 57.14%, lr: 0.000460419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 127.70batch/s, accuracy=59.2, loss=1.12]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 298.86batch/s, accuracy=57.6, val_loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, loss: 1.0013, acc: 59.18%, val_loss: 1.0717, val_acc: 57.64%, lr: 0.000442002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 124.87batch/s, accuracy=60.1, loss=0.721]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 252.99batch/s, accuracy=57.4, val_loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, loss: 0.9881, acc: 60.14%, val_loss: 1.0692, val_acc: 57.36%, lr: 0.000424322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:06<00:00, 114.09batch/s, accuracy=60.6, loss=0.852]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 317.09batch/s, accuracy=57.6, val_loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, loss: 0.9784, acc: 60.64%, val_loss: 1.0651, val_acc: 57.60%, lr: 0.000407349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 121.00batch/s, accuracy=60.6, loss=0.66]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 298.25batch/s, accuracy=57.8, val_loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, loss: 0.9715, acc: 60.61%, val_loss: 1.0700, val_acc: 57.82%, lr: 0.000391055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 119.00batch/s, accuracy=61.2, loss=0.73]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 306.32batch/s, accuracy=56.9, val_loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, loss: 0.9682, acc: 61.24%, val_loss: 1.0658, val_acc: 56.89%, lr: 0.000375413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 703/703 [00:05<00:00, 124.95batch/s, accuracy=61, loss=0.875]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 296.59batch/s, accuracy=57.2, val_loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, loss: 0.9665, acc: 60.98%, val_loss: 1.0643, val_acc: 57.18%, lr: 0.000360397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 117.51batch/s, accuracy=61.4, loss=0.939]\n",
      "100%|████████████████████████████████████████████████| 176/176 [00:00<00:00, 314.66batch/s, accuracy=57, val_loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, loss: 0.9545, acc: 61.42%, val_loss: 1.0719, val_acc: 57.04%, lr: 0.000345981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 128.45batch/s, accuracy=61.5, loss=0.968]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 314.87batch/s, accuracy=58.2, val_loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, loss: 0.9481, acc: 61.51%, val_loss: 1.0664, val_acc: 58.21%, lr: 0.000332142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 118.08batch/s, accuracy=61.6, loss=1.17]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 304.23batch/s, accuracy=58.1, val_loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, loss: 0.9407, acc: 61.58%, val_loss: 1.0711, val_acc: 58.14%, lr: 0.000318856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 127.12batch/s, accuracy=61.4, loss=1.04]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 312.36batch/s, accuracy=57.5, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, loss: 0.9423, acc: 61.35%, val_loss: 1.0671, val_acc: 57.53%, lr: 0.000306102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 121.86batch/s, accuracy=61.5, loss=1.16]\n",
      "100%|███████████████████████████████████████████████| 176/176 [00:00<00:00, 313.38batch/s, accuracy=58.4, val_loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, loss: 0.9400, acc: 61.55%, val_loss: 1.0683, val_acc: 58.42%, lr: 0.000293858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 703/703 [00:05<00:00, 132.46batch/s, accuracy=61.1, loss=1.47]\n",
      "100%|████████████████████████████████████████████████| 176/176 [00:00<00:00, 325.38batch/s, accuracy=58, val_loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, loss: 0.9319, acc: 61.15%, val_loss: 1.0656, val_acc: 58.00%, lr: 0.000282103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 703/703 [00:05<00:00, 130.17batch/s, accuracy=62.3, loss=1]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 318.36batch/s, accuracy=58.6, val_loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, loss: 0.9315, acc: 62.32%, val_loss: 1.0700, val_acc: 58.60%, lr: 0.000270819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 133.66batch/s, accuracy=62.2, loss=0.722]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 337.28batch/s, accuracy=58.4, val_loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, loss: 0.9256, acc: 62.21%, val_loss: 1.0841, val_acc: 58.35%, lr: 0.000259986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 128.16batch/s, accuracy=62.6, loss=0.703]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 315.72batch/s, accuracy=58.2, val_loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, loss: 0.9202, acc: 62.60%, val_loss: 1.0759, val_acc: 58.24%, lr: 0.000249587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 127.91batch/s, accuracy=63.2, loss=0.803]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 294.12batch/s, accuracy=58.5, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, loss: 0.9059, acc: 63.18%, val_loss: 1.0772, val_acc: 58.49%, lr: 0.000239603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 703/703 [00:05<00:00, 127.84batch/s, accuracy=63, loss=0.67]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 295.56batch/s, accuracy=58.3, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, loss: 0.9111, acc: 63.02%, val_loss: 1.0847, val_acc: 58.28%, lr: 0.000230019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 127.44batch/s, accuracy=63.3, loss=0.767]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 273.42batch/s, accuracy=58.3, val_loss=1.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, loss: 0.9097, acc: 63.26%, val_loss: 1.0769, val_acc: 58.28%, lr: 0.000220819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 126.98batch/s, accuracy=63.4, loss=0.762]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 294.16batch/s, accuracy=57.6, val_loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, loss: 0.8973, acc: 63.39%, val_loss: 1.0885, val_acc: 57.64%, lr: 0.000211986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:06<00:00, 116.54batch/s, accuracy=63.4, loss=0.935]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 292.08batch/s, accuracy=57.9, val_loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, loss: 0.8956, acc: 63.43%, val_loss: 1.0871, val_acc: 57.89%, lr: 0.000203506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 703/703 [00:05<00:00, 125.35batch/s, accuracy=63.7, loss=0.551]\n",
      "100%|██████████████████████████████████████████████| 176/176 [00:00<00:00, 289.47batch/s, accuracy=57.7, val_loss=1.46]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, loss: 0.8925, acc: 63.68%, val_loss: 1.0828, val_acc: 57.75%, lr: 0.000195366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to save metrics history\n",
    "history = {\n",
    "    'train_losses_cls': [],\n",
    "    'train_losses_reg': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'val_losses_cls': [],\n",
    "    'val_losses_reg': [],\n",
    "    'val_losses': [],\n",
    "    'val_accuracies': [],\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # # Create DataLoaders using the precomputed latents for each epoch\n",
    "    # train_lat_dataset = LatentDataset(train_latents[epoch%50], train_labels, train_labels_cnt_norm, train_filenames)\n",
    "    # train_lat_loader = DataLoader(train_lat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_loss_cls = 0.0\n",
    "    running_loss_reg = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    with tqdm(train_lat_loader, unit=\"batch\") as tepoch:\n",
    "        \n",
    "        # for images, targets_cls, targets_reg, _ in tepoch:\n",
    "        #     images, targets_cls, targets_reg = images.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "\n",
    "        for latents, targets_cls, targets_reg, _ in tepoch:\n",
    "            latents, targets_cls, targets_reg = latents.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs_cls, outputs_reg = model(latents)\n",
    "\n",
    "            # Compute losses\n",
    "            targets_reg = targets_reg.to(torch.float)  # Ensure targets_reg is Float\n",
    "            targets_reg = targets_reg.unsqueeze(1)\n",
    "            \n",
    "            mask_reg = targets_reg != 0\n",
    "            if mask_reg.any():\n",
    "                loss_reg = criterion_reg(outputs_reg[mask_reg], targets_reg[mask_reg]).mean()\n",
    "                \n",
    "                # weights = torch.tensor([class_weights[int(c)] for c in targets_cls], device=device).unsqueeze(1)\n",
    "                # loss_reg = (loss_reg_raw * weights[mask_reg]).mean()\n",
    "            else:\n",
    "                loss_reg = torch.tensor(0.0)  # Ignore zero targets\n",
    "                \n",
    "            loss_cls = criterion_cls(outputs_cls, targets_cls)\n",
    "            \n",
    "            loss = (loss_cls * weight['cls'] + loss_reg * weight['reg'])\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_loss_cls += loss_cls.item()\n",
    "            running_loss_reg += loss_reg.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs_cls, 1)\n",
    "            total_train += targets_cls.size(0)\n",
    "            correct_train += (predicted == targets_cls).sum().item()\n",
    "\n",
    "            # Update the progress bar\n",
    "            tepoch.set_postfix(\n",
    "                loss=loss.item(),\n",
    "                accuracy=100 * correct_train / total_train\n",
    "            )\n",
    "\n",
    "    avg_train_cls_loss = running_loss_cls / len(train_lat_loader)\n",
    "    avg_train_reg_loss = running_loss_reg / len(train_lat_loader)\n",
    "    avg_train_loss = running_loss / len(train_lat_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    running_val_cls_loss = 0.0\n",
    "    running_val_reg_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients for validation\n",
    "        with tqdm(valid_lat_loader, unit=\"batch\") as tepoch_val:\n",
    "            \n",
    "            # for images, targets_cls, targets_reg, _ in tepoch_val:\n",
    "            #     images, targets_cls, targets_reg = images.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "                \n",
    "            for latents, targets_cls, targets_reg, _ in tepoch_val:\n",
    "                latents, targets_cls, targets_reg = latents.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs_cls, outputs_reg = model(latents)\n",
    "\n",
    "                # Compute losses\n",
    "                targets_reg = targets_reg.to(torch.float)  # Ensure targets_reg is Float\n",
    "                targets_reg = targets_reg.unsqueeze(1)\n",
    "\n",
    "                mask_reg = targets_reg != 0\n",
    "                if mask_reg.any():\n",
    "                    loss_reg = criterion_reg(outputs_reg[mask_reg], targets_reg[mask_reg]).mean()\n",
    "\n",
    "                    # weights = torch.tensor([class_weights[int(c)] for c in targets_cls], device=device).unsqueeze(1)\n",
    "                    # loss_reg = (loss_reg_raw * weights[mask_reg]).mean()\n",
    "                else:\n",
    "                    loss_reg = torch.tensor(0.0, device=device)  # Ignore zero targets\n",
    "\n",
    "                loss_cls = criterion_cls(outputs_cls, targets_cls)\n",
    "                loss = (loss_cls * weight['cls'] + loss_reg * weight['reg'])\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "                running_val_cls_loss += loss_cls.item()\n",
    "                running_val_reg_loss += loss_reg.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs_cls, 1)\n",
    "                total_val += targets_cls.size(0)\n",
    "                correct_val += (predicted == targets_cls).sum().item()\n",
    "\n",
    "                # Update the progress bar\n",
    "                tepoch_val.set_postfix(\n",
    "                    val_loss=loss.item(),\n",
    "                    accuracy=100 * correct_val / total_val\n",
    "                )\n",
    "\n",
    "    avg_val_cls_loss = running_val_cls_loss / len(valid_lat_loader)\n",
    "    avg_val_reg_loss = running_val_reg_loss / len(valid_lat_loader)\n",
    "    avg_val_loss = running_val_loss / len(valid_lat_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, loss: {avg_train_loss:.4f}, acc: {train_accuracy:.2f}%, val_loss: {avg_val_loss:.4f}, val_acc: {val_accuracy:.2f}%, lr: {current_lr:.6g}')\n",
    "    \n",
    "    # Save the metrics\n",
    "    history['train_losses_cls'].append(avg_train_cls_loss)\n",
    "    history['train_losses_reg'].append(avg_train_reg_loss)\n",
    "    history['train_losses'].append(avg_train_loss)\n",
    "    history['train_accuracies'].append(train_accuracy)\n",
    "    history['val_losses_cls'].append(avg_val_cls_loss)\n",
    "    history['val_losses_reg'].append(avg_val_reg_loss)\n",
    "    history['val_losses'].append(avg_val_loss)\n",
    "    history['val_accuracies'].append(val_accuracy)\n",
    "    \n",
    "    # Step the scheduler after each epoch\n",
    "    lr_scheduler.step()\n",
    "    # lr_scheduler.step(metric=avg_val_cls_loss)\n",
    "\n",
    "    # Save each epoch's model\n",
    "    torch.save(model.state_dict(), 'outputs/run/model_epoch_' + str(epoch) + '.pth')\n",
    "\n",
    "    # Check early stopping after each epoch\n",
    "    if early_stopping(epoch, avg_val_cls_loss, val_accuracy):\n",
    "        print(\"Early stopping triggered! Loading best model.\")\n",
    "        # Save the last model weights\n",
    "        torch.save(model.state_dict(), 'outputs/last_head_model.pth')\n",
    "        # Load the best model weights\n",
    "        model.load_state_dict(early_stopping.best_model_weights)\n",
    "        break\n",
    "\n",
    "# Save the best model weights\n",
    "torch.save(model.state_dict(), 'outputs/best_head_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8421095-cfe3-47ff-96f8-779a697be3c0",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a7cdb-897c-4461-8110-5fdd895bcb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses and Accuracies\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses'], label='Train Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_accuracies'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracies'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf054ef-96e9-41ba-a566-ed46e710caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Additional Losses\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses_cls'], label='Train Loss (Class)')\n",
    "plt.plot(history['val_losses_cls'], label='Validation Loss (Class)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Classification Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_losses_reg'], label='Train Loss (Reg)')\n",
    "plt.plot(history['val_losses_reg'], label='Validation Loss (Reg)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Regression Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2809e24-ad8e-4a1f-862d-e8b5d8778637",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fae579e-a466-4f31-a314-cdaa787b6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed latent representations and labels\n",
    "test_data = torch.load('outputs/test_latents.pth', weights_only=True)\n",
    "# test_latents, test_glcm, test_lbp, test_labels, test_labels_cnt, test_filenames = test_data['latents'], test_data['glcm'], test_data['lbp'], test_data['labels'], test_data['labels_cnt'], test_data['filenames']\n",
    "test_latents, test_labels, test_labels_cnt, test_filenames = test_data['latents'], test_data['labels'], test_data['labels_cnt'], test_data['filenames']\n",
    "\n",
    "# Min-max normalization\n",
    "test_labels_cnt_norm = (test_labels_cnt - min_val) / (max_val - min_val)\n",
    "\n",
    "# Create DataLoaders using the precomputed latents\n",
    "# test_lat_dataset = LatentDataset(test_latents, test_glcm, test_lbp, test_labels, test_labels_cnt_norm, test_filenames)\n",
    "test_lat_dataset = LatentDataset(test_latents, test_labels, test_labels_cnt_norm, test_filenames)\n",
    "test_lat_loader = DataLoader(test_lat_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "366bba86-c2dc-4011-9962-a2205876c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_7028\\1297779379.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('outputs/best_head_model.pth')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the FireRisk_Head model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "checkpoint = torch.load('outputs/best_head_model.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "\n",
    "# # Initialize the combined model with the MAE encoder and FireRisk_Head weights\n",
    "# full_model = FireRisk_Full(mae_model=mae_model, head_model=model, num_classes=7)\n",
    "# full_model = full_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f1243df-5abe-4705-90c4-5bdea63adb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion_cls, criterion_reg, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_loss_reg = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "            for images, targets, _, filenames in tepoch:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs_cls, outputs_reg = model(images)\n",
    "\n",
    "                # Calculate loss\n",
    "                targets_reg = targets.to(torch.float).unsqueeze(1)\n",
    "                mask_reg = targets_reg != 0\n",
    "                \n",
    "                if mask_reg.any():\n",
    "                    loss_reg = criterion_reg(outputs_reg[mask_reg], targets_reg[mask_reg]).mean()\n",
    "                else:\n",
    "                    loss_reg = torch.tensor(0.0, device=device)\n",
    "                    \n",
    "                loss_cls = criterion_cls(outputs_cls, targets)\n",
    "\n",
    "                running_loss += loss_cls.item()\n",
    "                running_loss_reg += loss_reg.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs_cls, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(targets.cpu().numpy())\n",
    "                all_filenames.extend(filenames)\n",
    "\n",
    "                # Update the tqdm progress bar\n",
    "                tepoch.set_postfix(loss=loss_cls.item(), accuracy=100 * correct / total)\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    avg_loss_reg = running_loss_reg / len(data_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, avg_loss_reg, accuracy, all_preds, all_labels, all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38afe3b8-ecc5-4c97-b1c5-6a415c8d3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_7028\\1242397847.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('outputs/run/model_epoch_' + str(i) + '.pth')\n",
      "100%|████████████████████████████████████████████████| 1347/1347 [00:05<00:00, 244.78batch/s, accuracy=54.9, loss=0.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Test Loss: 1.2165, Test Loss Reg: 0.0556, Test Accuracy: 54.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:05<00:00, 236.59batch/s, accuracy=56.8, loss=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Test Loss: 1.1457, Test Loss Reg: 0.0542, Test Accuracy: 56.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 231.44batch/s, accuracy=56.2, loss=0.0509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Test Loss: 1.1332, Test Loss Reg: 0.0488, Test Accuracy: 56.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 227.14batch/s, accuracy=58.7, loss=0.0371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Test Loss: 1.0923, Test Loss Reg: 0.0506, Test Accuracy: 58.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:06<00:00, 219.53batch/s, accuracy=56.4, loss=0.0282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Test Loss: 1.0966, Test Loss Reg: 0.0431, Test Accuracy: 56.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 247.26batch/s, accuracy=59.4, loss=0.0086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Test Loss: 1.0670, Test Loss Reg: 0.0505, Test Accuracy: 59.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 243.21batch/s, accuracy=56.7, loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Test Loss: 1.1004, Test Loss Reg: 0.0478, Test Accuracy: 56.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 235.55batch/s, accuracy=59.4, loss=0.0196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Test Loss: 1.0651, Test Loss Reg: 0.0424, Test Accuracy: 59.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 242.21batch/s, accuracy=58.9, loss=0.00659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Test Loss: 1.0625, Test Loss Reg: 0.0438, Test Accuracy: 58.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 250.47batch/s, accuracy=56.3, loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Test Loss: 1.0984, Test Loss Reg: 0.0457, Test Accuracy: 56.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 245.31batch/s, accuracy=57.3, loss=0.0155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Test Loss: 1.0894, Test Loss Reg: 0.0448, Test Accuracy: 57.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 263.95batch/s, accuracy=58.3, loss=0.00531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Test Loss: 1.0678, Test Loss Reg: 0.0453, Test Accuracy: 58.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 297.10batch/s, accuracy=59.6, loss=0.00574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Test Loss: 1.0521, Test Loss Reg: 0.0437, Test Accuracy: 59.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 237.78batch/s, accuracy=57.5, loss=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Test Loss: 1.0845, Test Loss Reg: 0.0440, Test Accuracy: 57.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 1347/1347 [00:05<00:00, 236.33batch/s, accuracy=58, loss=0.0292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Test Loss: 1.0639, Test Loss Reg: 0.0424, Test Accuracy: 57.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 245.19batch/s, accuracy=59.3, loss=0.00873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Test Loss: 1.0456, Test Loss Reg: 0.0417, Test Accuracy: 59.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:05<00:00, 238.25batch/s, accuracy=58, loss=0.00792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Test Loss: 1.0687, Test Loss Reg: 0.0420, Test Accuracy: 57.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:05<00:00, 236.00batch/s, accuracy=59.6, loss=0.0142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Test Loss: 1.0412, Test Loss Reg: 0.0414, Test Accuracy: 59.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 247.33batch/s, accuracy=59.6, loss=0.00264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Test Loss: 1.0339, Test Loss Reg: 0.0408, Test Accuracy: 59.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 246.49batch/s, accuracy=58.9, loss=0.00305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Test Loss: 1.0502, Test Loss Reg: 0.0415, Test Accuracy: 58.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 239.75batch/s, accuracy=59.6, loss=0.00841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Test Loss: 1.0333, Test Loss Reg: 0.0399, Test Accuracy: 59.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 302.05batch/s, accuracy=58.6, loss=0.00726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Test Loss: 1.0617, Test Loss Reg: 0.0414, Test Accuracy: 58.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 314.23batch/s, accuracy=58.7, loss=0.00112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Test Loss: 1.0597, Test Loss Reg: 0.0397, Test Accuracy: 58.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 305.33batch/s, accuracy=59.4, loss=0.00515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Test Loss: 1.0425, Test Loss Reg: 0.0391, Test Accuracy: 59.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1347/1347 [00:04<00:00, 307.36batch/s, accuracy=59, loss=0.00681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Test Loss: 1.0518, Test Loss Reg: 0.0409, Test Accuracy: 59.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 295.69batch/s, accuracy=58.8, loss=0.00447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Test Loss: 1.0495, Test Loss Reg: 0.0408, Test Accuracy: 58.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 315.43batch/s, accuracy=59.1, loss=0.00129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Test Loss: 1.0445, Test Loss Reg: 0.0399, Test Accuracy: 59.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 268.94batch/s, accuracy=59.8, loss=0.00119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Test Loss: 1.0372, Test Loss Reg: 0.0396, Test Accuracy: 59.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 300.99batch/s, accuracy=59.6, loss=0.00334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Test Loss: 1.0413, Test Loss Reg: 0.0385, Test Accuracy: 59.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:04<00:00, 324.57batch/s, accuracy=59.8, loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Test Loss: 1.0452, Test Loss Reg: 0.0400, Test Accuracy: 59.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 298.53batch/s, accuracy=58.7, loss=0.00872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Test Loss: 1.0593, Test Loss Reg: 0.0394, Test Accuracy: 58.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 311.50batch/s, accuracy=59.7, loss=0.00205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Test Loss: 1.0320, Test Loss Reg: 0.0390, Test Accuracy: 59.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 316.02batch/s, accuracy=59.7, loss=0.00531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Test Loss: 1.0403, Test Loss Reg: 0.0387, Test Accuracy: 59.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1347/1347 [00:04<00:00, 313.41batch/s, accuracy=60.3, loss=0.000653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Test Loss: 1.0314, Test Loss Reg: 0.0390, Test Accuracy: 60.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 319.66batch/s, accuracy=59.8, loss=0.00194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Test Loss: 1.0370, Test Loss Reg: 0.0381, Test Accuracy: 59.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 308.54batch/s, accuracy=60.6, loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Test Loss: 1.0240, Test Loss Reg: 0.0380, Test Accuracy: 60.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 313.00batch/s, accuracy=59.5, loss=0.00167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Test Loss: 1.0582, Test Loss Reg: 0.0388, Test Accuracy: 59.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 265.88batch/s, accuracy=59.4, loss=0.00331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Test Loss: 1.0575, Test Loss Reg: 0.0392, Test Accuracy: 59.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 235.10batch/s, accuracy=59.5, loss=0.00308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Test Loss: 1.0436, Test Loss Reg: 0.0380, Test Accuracy: 59.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 291.55batch/s, accuracy=59.8, loss=0.00252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Test Loss: 1.0520, Test Loss Reg: 0.0390, Test Accuracy: 59.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 309.88batch/s, accuracy=59.4, loss=0.00392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Test Loss: 1.0516, Test Loss Reg: 0.0390, Test Accuracy: 59.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 323.85batch/s, accuracy=59.2, loss=0.00156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Test Loss: 1.0669, Test Loss Reg: 0.0381, Test Accuracy: 59.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:04<00:00, 318.21batch/s, accuracy=60.5, loss=0.0043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Test Loss: 1.0450, Test Loss Reg: 0.0383, Test Accuracy: 60.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1347/1347 [00:04<00:00, 290.83batch/s, accuracy=60.4, loss=0.0034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Test Loss: 1.0537, Test Loss Reg: 0.0390, Test Accuracy: 60.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:05<00:00, 247.49batch/s, accuracy=60.2, loss=0.00412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Test Loss: 1.0537, Test Loss Reg: 0.0376, Test Accuracy: 60.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 294.36batch/s, accuracy=59.6, loss=0.00165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Test Loss: 1.0555, Test Loss Reg: 0.0379, Test Accuracy: 59.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1347/1347 [00:05<00:00, 251.85batch/s, accuracy=59.5, loss=0.000335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Test Loss: 1.0622, Test Loss Reg: 0.0376, Test Accuracy: 59.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1347/1347 [00:04<00:00, 301.42batch/s, accuracy=60.4, loss=0.00118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Test Loss: 1.0510, Test Loss Reg: 0.0374, Test Accuracy: 60.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1347/1347 [00:04<00:00, 312.52batch/s, accuracy=59.6, loss=0.000264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Test Loss: 1.0667, Test Loss Reg: 0.0380, Test Accuracy: 59.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1347/1347 [00:04<00:00, 313.95batch/s, accuracy=59.4, loss=0.000707]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Test Loss: 1.0667, Test Loss Reg: 0.0377, Test Accuracy: 59.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test dataset\n",
    "all_test_loss = []\n",
    "all_test_loss_reg = []\n",
    "all_test_accuracy = []\n",
    "all_test_preds = []\n",
    "all_test_labels = []\n",
    "all_test_filenames = []\n",
    "\n",
    "epochs_count = sum(\n",
    "    1 for filename in os.listdir(checkpoints_path)\n",
    "    if os.path.isfile(os.path.join(checkpoints_path, filename))\n",
    ")\n",
    "\n",
    "for i in range(epochs_count):\n",
    "    checkpoint = torch.load('outputs/run/model_epoch_' + str(i) + '.pth')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    test_loss, test_loss_reg, test_accuracy, test_preds, test_labels, test_filenames = evaluate(model, test_lat_loader, criterion_cls, criterion_reg, device)\n",
    "    all_test_loss.append(test_loss)\n",
    "    all_test_loss_reg.append(test_loss_reg)\n",
    "    all_test_accuracy.append(test_accuracy)\n",
    "    all_test_preds.append(test_preds)\n",
    "    all_test_labels.append(test_labels)\n",
    "    all_test_filenames.append(test_filenames)\n",
    "    print(f\"Epoch {i+1}, Test Loss: {test_loss:.4f}, Test Loss Reg: {test_loss_reg:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c675e5-97fa-46a0-8828-637dd58cfb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses and Accuracies\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(all_test_loss, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Testing Loss')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(all_test_loss_reg, label='Reg Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Reg Loss')\n",
    "plt.legend()\n",
    "plt.title('Testing Reg Loss')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(all_test_accuracy, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Testing Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15fd53-7060-429c-875d-ca835f5899bb",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f143d1d-8fb4-49e5-b213-24395532b7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch with highest accuracy: 36\n"
     ]
    }
   ],
   "source": [
    "# Search the best performing epoch\n",
    "best_epoch = all_test_accuracy.index(max(all_test_accuracy))\n",
    "print(\"Epoch with highest accuracy:\", best_epoch+1)\n",
    "test_loss, test_accuracy, test_preds, test_labels, test_filenames = all_test_loss[best_epoch], all_test_accuracy[best_epoch], all_test_preds[best_epoch], all_test_labels[best_epoch], all_test_filenames[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55abec-b0a6-42d3-82ca-f507cafd9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bb2d613-4077-4a9a-a8ad-48a7b296ec47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8438    0.8510    0.8474       584\n",
      "           1     0.7762    0.8686    0.8198      5091\n",
      "           2     0.6724    0.7582    0.7127      8448\n",
      "           3     0.3246    0.1808    0.2323      2599\n",
      "           4     0.2149    0.1366    0.1670      1772\n",
      "           5     0.3050    0.3686    0.3338      1609\n",
      "           6     0.3474    0.2928    0.3177      1438\n",
      "\n",
      "    accuracy                         0.6058     21541\n",
      "   macro avg     0.4978    0.4938    0.4901     21541\n",
      "weighted avg     0.5729    0.6058    0.5842     21541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(test_labels, test_preds, digits=4)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2f511-3923-4f79-b091-dae16392f383",
   "metadata": {},
   "source": [
    "### Save session results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "048e83ca-3ac9-4a6e-9516-f9d3068bde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame({\n",
    "    'Filename': test_filenames,\n",
    "    'Label': test_labels,\n",
    "    'Prediction': test_preds\n",
    "})\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "test_results.to_csv('outputs/test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebfe369e-17b2-4887-84fd-6990f4970d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv('outputs/history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3afda9b-8a67-4d36-97f6-971a9dc394b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_results = pd.DataFrame({\n",
    "    'all_test_loss': all_test_loss,\n",
    "    'all_test_loss_reg': all_test_loss_reg,\n",
    "    'all_test_accuracy': all_test_accuracy\n",
    "})\n",
    "all_test_results.to_csv('outputs/all_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e8029-a314-42d7-983e-da09ef5118e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
