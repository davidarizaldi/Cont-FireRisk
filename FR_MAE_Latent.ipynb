{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4173c20e-19af-4b0c-ae90-acffa873adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f8697f-dd0e-45ad-b441-06259fcccfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('outputs/run', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7fa16-8867-4f7b-a0a5-fea09a0cd05f",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e759250-6143-44e5-91e8-18ab147380fc",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b29ccbb-bfff-455d-9363-c843f2e0240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_the_data(data_dir):\n",
    "    # Generate data paths with labels\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    # Get folder names\n",
    "    folds = os.listdir(data_dir)\n",
    "\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(data_dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            \n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Concatenate data paths with labels into one DataFrame\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "\n",
    "    df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3055c21-3c9b-42dc-9fba-6154c973c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths labels\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...   High\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...   High\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...   High\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...   High\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...   High\n",
       "...                                                  ...    ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...  Water\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...  Water\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...  Water\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...  Water\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...  Water\n",
       "\n",
       "[70331 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = 'FireRisk'\n",
    "\n",
    "train_df = loading_the_data(dir + '\\\\train')\n",
    "test_df = loading_the_data(dir + '\\\\val')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647db0fe-26e4-4669-b003-a6dd89d271ba",
   "metadata": {},
   "source": [
    "## Menambahkan Label Kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b3f8da-d198-4ed3-8b49-c7c1f44ee4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>High</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>High</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>High</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>High</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>High</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>Water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...   High        1237\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...   High         628\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...   High         718\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...   High         805\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...   High        1093\n",
       "...                                                  ...    ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...  Water           0\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...  Water           0\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...  Water           0\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...  Water           0\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...  Water           0\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_df = pd.read_csv(\"conversion_cnt.csv\")\n",
    "train_df = pd.merge(train_df, cnt_df[['filepaths', 'grid_code']], on='filepaths', how='left')\n",
    "train_df.rename(columns={'grid_code': 'labels_cnt'}, inplace=True)\n",
    "\n",
    "cnt_df = pd.read_csv(\"conversion_test_cnt.csv\")\n",
    "test_df = pd.merge(test_df, cnt_df[['filepaths', 'grid_code']], on='filepaths', how='left')\n",
    "test_df.rename(columns={'grid_code': 'labels_cnt'}, inplace=True)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cd264-c136-4250-8d47-676931e85c93",
   "metadata": {},
   "source": [
    "## Encoding Label Kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1589d6c9-9119-48c3-80b8-242527545771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>5</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>5</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>5</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>5</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>5</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths  labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...       5        1237\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...       5         628\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...       5         718\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...       5         805\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...       5        1093\n",
       "...                                                  ...     ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...       0           0\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...       0           0\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...       0           0\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...       0           0\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...       0           0\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['Water', 'Non-burnable', 'Very_Low', 'Low', 'Moderate', 'High', 'Very_High']\n",
    "label_encoder = OrdinalEncoder(categories=[class_names])\n",
    "\n",
    "train_df['labels'] = label_encoder.fit_transform(train_df[['labels']])\n",
    "test_df['labels'] = label_encoder.transform(test_df[['labels']])\n",
    "\n",
    "train_df['labels'] = train_df['labels'].astype('int64')\n",
    "test_df['labels'] = test_df['labels'].astype('int64')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f915ea-f879-4911-b838-280fd32e721f",
   "metadata": {},
   "source": [
    "## Normalisasi Label Kontinu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff320c9-4cd2-4da6-80c9-246406a8764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cont_label(label):\n",
    "    if label <= 0:\n",
    "        return 0\n",
    "    elif label <= 61:\n",
    "        return label / 61\n",
    "    elif 61 < label <= 178:\n",
    "        return (label - 61) / (178 - 61) + 1\n",
    "    elif 178 < label <= 489:\n",
    "        return (label - 178) / (489 - 178) + 2\n",
    "    elif 489 < label <= 1985:\n",
    "        return (label - 489) / (1985 - 489) + 3\n",
    "    elif 1985 < label:\n",
    "        return (label - 1985) / (100000 - 1985) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da81a0b7-a451-4a20-a207-9d4985c1a8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70326</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70327</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70328</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70329</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70330</th>\n",
       "      <td>G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70331 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepaths  labels  labels_cnt\n",
       "0      G:\\FireRisk\\train\\High\\27032281_4_-103.4304412...       5       3.500\n",
       "1      G:\\FireRisk\\train\\High\\27038991_4_-77.77273442...       5       3.093\n",
       "2      G:\\FireRisk\\train\\High\\27040201_4_-73.83896834...       5       3.153\n",
       "3      G:\\FireRisk\\train\\High\\27042071_4_-122.1662712...       5       3.211\n",
       "4      G:\\FireRisk\\train\\High\\27042401_4_-121.1231610...       5       3.404\n",
       "...                                                  ...     ...         ...\n",
       "70326  G:\\FireRisk\\train\\Water\\35471591_7_-72.4088150...       0       0.000\n",
       "70327  G:\\FireRisk\\train\\Water\\35484351_7_-82.8478475...       0       0.000\n",
       "70328  G:\\FireRisk\\train\\Water\\35487101_7_-72.1588909...       0       0.000\n",
       "70329  G:\\FireRisk\\train\\Water\\35497331_7_-90.9452064...       0       0.000\n",
       "70330  G:\\FireRisk\\train\\Water\\35497991_7_-88.7518081...       0       0.000\n",
       "\n",
       "[70331 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['labels_cnt'] = train_df['labels_cnt'].apply(normalize_cont_label).round(3)\n",
    "test_df['labels_cnt'] = test_df['labels_cnt'].apply(normalize_cont_label).round(3)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e771df4-4b3b-4853-b22a-960f9599f7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70331.000000</td>\n",
       "      <td>70331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.547156</td>\n",
       "      <td>1.109816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.498586</td>\n",
       "      <td>1.271991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.576000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             labels    labels_cnt\n",
       "count  70331.000000  70331.000000\n",
       "mean       2.547156      1.109816\n",
       "std        1.498586      1.271991\n",
       "min        0.000000      0.000000\n",
       "25%        1.000000      0.000000\n",
       "50%        2.000000      0.557000\n",
       "75%        4.000000      2.035000\n",
       "max        6.000000      4.576000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12d92e-2e88-4f03-b164-8703b5582a0b",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e874d1dd-5ed8-41bf-bb43-2839facba937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unused = 0.98\n",
    "# train_df, unused_df = train_test_split(train_df, test_size = unused, shuffle = True, random_state = 49, stratify=train_df['labels'])\n",
    "# test_df, unused_df = train_test_split(test_df, test_size = unused, shuffle = True, random_state = 49, stratify=test_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b6ef42-7e5e-40cd-b144-d6521040fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size = 0.2, shuffle = True, random_state = 49, stratify=train_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34d75c98-3f25-464a-8675-c8026c17fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_autopct(pct):\n",
    "#     total = sum(data_balance)\n",
    "#     val = int(round(pct*total/100.0))\n",
    "#     return \"{:.1f}%\\n({:d})\".format(pct, val)\n",
    "\n",
    "# data_balance = train_df.labels.value_counts()\n",
    "# data_distribution = [train_df.size, valid_df.size]\n",
    "\n",
    "# plt.pie(data_distribution, labels = ['train', 'valid'], autopct=custom_autopct, colors = [\"#57A6DE\",\"#5D57DE\",\"#577BDE\",\"#43CFE0\",\"#A0B1DE\"])\n",
    "# plt.title(\"Data distribution\")\n",
    "# plt.axis(\"equal\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a9095-afb1-4ea3-9a93-b004ee63ddbb",
   "metadata": {},
   "source": [
    "## Augmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "251c7779-3897-4cbe-a5d0-2751683d586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRiskDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the file path and label for the index\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "        label_cnt = self.dataframe.iloc[idx, 2]\n",
    "        \n",
    "        # Open the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # If there is any transform (e.g., normalization, augmentation), apply it\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, label_cnt, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492f7bd1-964e-44d2-a42e-354aceb81d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    # transforms.CenterCrop(224),  # Crop image to get 224x224 in the center\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.RandomHorizontalFlip(p=0.2),  # Randomly flip image horizontally\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.03125, 0.03125), fill=(0, 0, 0)),  # Random affine transformations (rotation, translation)\n",
    "    # transforms.CenterCrop(224),  # Crop image to get 224x224 in the center\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = FireRiskDataset(dataframe=train_df, transform=augment)\n",
    "valid_dataset = FireRiskDataset(dataframe=valid_df, transform=transform)\n",
    "test_dataset = FireRiskDataset(dataframe=test_df, transform=transform)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a4dcd9-ec34-406a-9dbe-4a27b213cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(img):\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Convert CHW to HWC format\n",
    "#     plt.show()\n",
    "\n",
    "# # Get a batch of training data and displaying it\n",
    "# data_iter = iter(train_loader)\n",
    "# images, labels, labels_cnt, _ = next(data_iter)\n",
    "# imshow(torchvision.utils.make_grid(images[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a073ee-dd4e-42c4-b254-ba2b1a2349a6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e4d061-ce5b-479f-8e91-aa48d555426a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in globals() and model != None:\n",
    "    model.cpu()\n",
    "    del model\n",
    "if 'mae_model' in globals() and mae_model != None:\n",
    "    mae_model.cpu()\n",
    "    del mae_model\n",
    "if 'full_model' in globals() and full_model != None:\n",
    "    full_model.cpu()\n",
    "    del full_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e88fa0-61ea-4303-9aad-7e138389e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07a0cc-f136-45d4-9b0a-bb7386d1951f",
   "metadata": {},
   "source": [
    "## MAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aabd681d-dbf1-48df-812c-da0cd017d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAE model\n",
    "mae_model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "checkpoint = torch.load('mae_pretrain_vit_base.pth', weights_only=True)\n",
    "state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "mae_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Remove the final classification head (to use only the encoder part)\n",
    "mae_model.reset_classifier(0)\n",
    "mae_model = mae_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4763b4e-84d8-4199-ab08-47b55701bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters in the encoder\n",
    "for param in mae_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60ab043a-6dde-44f8-a0f5-85fd7f4ec5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VisionTransformer                        [16, 768]                 152,064\n",
       "â”œâ”€PatchEmbed: 1-1                        [16, 196, 768]            --\n",
       "â”‚    â””â”€Conv2d: 2-1                       [16, 768, 14, 14]         (590,592)\n",
       "â”‚    â””â”€Identity: 2-2                     [16, 196, 768]            --\n",
       "â”œâ”€Dropout: 1-2                           [16, 197, 768]            --\n",
       "â”œâ”€Identity: 1-3                          [16, 197, 768]            --\n",
       "â”œâ”€Identity: 1-4                          [16, 197, 768]            --\n",
       "â”œâ”€Sequential: 1-5                        [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-3                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-1               [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-2               [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-3                [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-4                [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-5               [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-6                     [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-7                [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-8                [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-4                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-9               [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-10              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-11               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-12               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-13              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-14                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-15               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-16               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-5                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-17              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-18              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-19               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-20               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-21              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-22                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-23               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-24               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-6                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-25              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-26              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-27               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-28               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-29              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-30                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-31               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-32               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-7                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-33              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-34              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-35               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-36               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-37              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-38                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-39               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-40               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-8                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-41              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-42              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-43               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-44               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-45              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-46                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-47               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-48               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-9                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-49              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-50              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-51               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-52               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-53              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-54                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-55               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-56               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-10                       [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-57              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-58              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-59               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-60               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-61              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-62                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-63               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-64               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-11                       [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-65              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-66              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-67               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-68               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-69              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-70                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-71               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-72               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-12                       [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-73              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-74              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-75               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-76               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-77              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-78                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-79               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-80               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-13                       [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-81              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-82              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-83               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-84               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-85              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-86                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-87               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-88               [16, 197, 768]            --\n",
       "â”‚    â””â”€Block: 2-14                       [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-89              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Attention: 3-90              [16, 197, 768]            (2,362,368)\n",
       "â”‚    â”‚    â””â”€Identity: 3-91               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-92               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€LayerNorm: 3-93              [16, 197, 768]            (1,536)\n",
       "â”‚    â”‚    â””â”€Mlp: 3-94                    [16, 197, 768]            (4,722,432)\n",
       "â”‚    â”‚    â””â”€Identity: 3-95               [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Identity: 3-96               [16, 197, 768]            --\n",
       "â”œâ”€LayerNorm: 1-6                         [16, 197, 768]            (1,536)\n",
       "â”œâ”€Identity: 1-7                          [16, 768]                 --\n",
       "â”œâ”€Dropout: 1-8                           [16, 768]                 --\n",
       "â”œâ”€Identity: 1-9                          [16, 768]                 --\n",
       "==========================================================================================\n",
       "Total params: 85,798,656\n",
       "Trainable params: 0\n",
       "Non-trainable params: 85,798,656\n",
       "Total mult-adds (G): 3.21\n",
       "==========================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2594.93\n",
       "Params size (MB): 342.59\n",
       "Estimated Total Size (MB): 2947.15\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mae_model, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e7152-31b9-460e-9695-2f04e8499b0e",
   "metadata": {},
   "source": [
    "## Latent Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86dafcd7-7d6c-4548-8e53-aeb2899b0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_representations(dataloader, model, device, epoch=1):\n",
    "    model.eval()\n",
    "    latent_representations = []\n",
    "    multi_latents = []\n",
    "    labels = []\n",
    "    labels_cnt = []\n",
    "    filenames = []\n",
    "\n",
    "    glcm_features = []\n",
    "    multi_glcm = []\n",
    "    lbp_features = []\n",
    "    multi_lbp = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets, targets_cnt, filename in tqdm(dataloader, unit=\"batch\"):\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass through the MAE encoder\n",
    "            latent = model(images)\n",
    "            latent_representations.append(latent.cpu())\n",
    "\n",
    "            # Extract GLCM and LBP\n",
    "            for i in range(images.size(0)):\n",
    "                glcm_feat, lbp_feat = extract_texture_features(images[i])\n",
    "                glcm_features.append(glcm_feat)\n",
    "                lbp_features.append(lbp_feat)\n",
    "\n",
    "            labels.extend(targets)\n",
    "            labels_cnt.extend(targets_cnt)\n",
    "            filenames.extend(filename)\n",
    "\n",
    "    # Concatenate the results across batches\n",
    "    latent_representations = torch.cat(latent_representations, dim=0)\n",
    "    glcm_features = torch.tensor(glcm_features)\n",
    "    lbp_features = torch.tensor(lbp_features)\n",
    "    \n",
    "    if epoch == 1:\n",
    "        return latent_representations, glcm_features, lbp_features, labels, labels_cnt, filenames\n",
    "    \n",
    "    multi_latents.append(latent_representations)\n",
    "    multi_glcm.append(glcm_features)\n",
    "    multi_lbp.append(lbp_features)\n",
    "    \n",
    "    while epoch > 1:\n",
    "        latent_representations = []\n",
    "        glcm_features = []\n",
    "        lbp_features = []\n",
    "        with torch.no_grad():\n",
    "            for images, targets, targets_cnt, filename in tqdm(dataloader, unit=\"batch\"):\n",
    "                images = images.to(device)\n",
    "    \n",
    "                # Forward pass through the MAE encoder\n",
    "                latent = model(images)\n",
    "                latent_representations.append(latent.cpu())\n",
    "\n",
    "                # Extract GLCM and LBP\n",
    "                for i in range(images.size(0)):\n",
    "                    glcm_feat, lbp_feat = extract_texture_features(images[i])\n",
    "                    glcm_features.append(glcm_feat)\n",
    "                    lbp_features.append(lbp_feat)\n",
    "    \n",
    "        # Concatenate the results across batches\n",
    "        latent_representations = torch.cat(latent_representations, dim=0)\n",
    "        glcm_features = torch.tensor(glcm_features)\n",
    "        lbp_features = torch.tensor(lbp_features)\n",
    "        \n",
    "        multi_latents.append(latent_representations)\n",
    "        multi_glcm.append(glcm_features)\n",
    "        multi_lbp.append(lbp_features)\n",
    "        epoch -= 1\n",
    "\n",
    "    return multi_latents, multi_glcm, multi_lbp, labels, labels_cnt, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41935a0d-6842-40f8-9e31-9edb5cae0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract latent representations for the training and validation datasets\n",
    "# train_latents, train_glcm, train_lbp, train_labels, train_labels_cnt, train_filenames = extract_latent_representations(train_loader, mae_model, device, 50)\n",
    "# torch.save({'latents': train_latents, 'glcm': train_glcm, 'lbp': train_lbp, 'labels': train_labels, 'labels_cnt': train_labels_cnt, 'filenames': train_filenames}, 'outputs/train_latents.pth')\n",
    "\n",
    "# valid_latents, valid_glcm, valid_lbp, valid_labels, valid_labels_cnt, valid_filenames = extract_latent_representations(valid_loader, mae_model, device)\n",
    "# torch.save({'latents': valid_latents, 'glcm': valid_glcm, 'lbp': valid_lbp, 'labels': valid_labels, 'labels_cnt': valid_labels_cnt, 'filenames': valid_filenames}, 'outputs/valid_latents.pth')\n",
    "\n",
    "# test_latents, test_glcm, test_lbp, test_labels, test_labels_cnt, test_filenames = extract_latent_representations(test_loader, mae_model, device)\n",
    "# torch.save({'latents': test_latents, 'glcm': test_glcm, 'lbp': test_lbp, 'labels': test_labels, 'labels_cnt': test_labels_cnt, 'filenames': test_filenames}, 'outputs/test_latents.pth')\n",
    "\n",
    "# print(len(train_latents))\n",
    "# print(valid_latents.shape)\n",
    "# print(test_latents.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e1136-1e10-46e8-a901-8bfa49d4d9b8",
   "metadata": {},
   "source": [
    "## Head Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "703d4a06-456e-4462-ab69-cc9f0798259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRisk_Head(nn.Module):\n",
    "    def __init__(self, num_classes=7, dropout_prob=0.5, latent_dim=768, glcm_dim=6, lbp_dim=9):\n",
    "        super(FireRisk_Head, self).__init__()\n",
    "\n",
    "        input_dim = latent_dim\n",
    "        # input_dim = input_dim + glcm_dim + lbp_dim\n",
    "        \n",
    "        # Shared layers\n",
    "        self.shared = nn.Module()\n",
    "        \n",
    "        # From latent representation to 512 neurons\n",
    "        self.shared.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.shared.bn1 = nn.BatchNorm1d(512)\n",
    "        self.shared.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # # From 512 neurons to 256 neurons\n",
    "        # self.shared.fc2 = nn.Linear(512, 256)\n",
    "        # self.shared.bn2 = nn.BatchNorm1d(256)\n",
    "        # self.shared.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # Classification module\n",
    "        self.classification = nn.Module()\n",
    "        self.classification.fc1 = nn.Linear(512, 128)\n",
    "        self.classification.bn1 = nn.BatchNorm1d(128)\n",
    "        self.classification.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.classification.head = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Fully connected layer (512 neurons)\n",
    "        x = self.shared.fc1(x)\n",
    "        x = self.shared.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.shared.dropout1(x)\n",
    "\n",
    "        # # Fully connected layer (256 neurons)\n",
    "        # x = self.shared.fc2(x)\n",
    "        # x = self.shared.bn2(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.shared.dropout2(x)\n",
    "\n",
    "        # Classification head (7 classes)\n",
    "        cls = self.classification.fc1(x)\n",
    "        cls = self.classification.bn1(cls)\n",
    "        cls = torch.relu(cls)\n",
    "        cls = self.classification.dropout1(cls)\n",
    "        cls = self.classification.head(cls)\n",
    "        \n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6582b012-80d9-479e-bba8-e3cc4d113e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FireRisk_Head                            [16, 7]                   --\n",
       "â”œâ”€Module: 1-1                            --                        --\n",
       "â”‚    â””â”€Linear: 2-1                       [16, 512]                 393,728\n",
       "â”‚    â””â”€BatchNorm1d: 2-2                  [16, 512]                 1,024\n",
       "â”‚    â””â”€Dropout: 2-3                      [16, 512]                 --\n",
       "â”œâ”€Module: 1-2                            --                        --\n",
       "â”‚    â””â”€Linear: 2-4                       [16, 128]                 65,664\n",
       "â”‚    â””â”€BatchNorm1d: 2-5                  [16, 128]                 256\n",
       "â”‚    â””â”€Dropout: 2-6                      [16, 128]                 --\n",
       "â”‚    â””â”€Linear: 2-7                       [16, 7]                   903\n",
       "==========================================================================================\n",
       "Total params: 461,575\n",
       "Trainable params: 461,575\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 7.39\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.16\n",
       "Params size (MB): 1.85\n",
       "Estimated Total Size (MB): 2.06\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "summary(model, input_size=(batch_size, 768))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75d65a-76ba-4fc5-af2b-f033b1540689",
   "metadata": {},
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02fe5a24-1a05-4e93-85ef-3b7dd533ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireRisk_Full(nn.Module):\n",
    "    def __init__(self, mae_model, head_model, num_classes=7, dropout_prob=0.5):\n",
    "        super(FireRisk_Full, self).__init__()\n",
    "        \n",
    "        # MAE encoder\n",
    "        self.mae_encoder = mae_model\n",
    "        \n",
    "        # Prediction head\n",
    "        self.head = head_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the MAE encoder to get the latent representation\n",
    "        x = self.mae_encoder(x)\n",
    "\n",
    "        # Prediction head\n",
    "        cls = self.head(x)\n",
    "        \n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef030340-6592-4f5d-bbef-42df62f5dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "FireRisk_Full                                 [16, 7]                   --\n",
       "â”œâ”€VisionTransformer: 1-1                      [16, 768]                 152,064\n",
       "â”‚    â””â”€PatchEmbed: 2-1                        [16, 196, 768]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-1                       [16, 768, 14, 14]         (590,592)\n",
       "â”‚    â”‚    â””â”€Identity: 3-2                     [16, 196, 768]            --\n",
       "â”‚    â””â”€Dropout: 2-2                           [16, 197, 768]            --\n",
       "â”‚    â””â”€Identity: 2-3                          [16, 197, 768]            --\n",
       "â”‚    â””â”€Identity: 2-4                          [16, 197, 768]            --\n",
       "â”‚    â””â”€Sequential: 2-5                        [16, 197, 768]            --\n",
       "â”‚    â”‚    â””â”€Block: 3-3                        [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-4                        [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-5                        [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-6                        [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-7                        [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-8                        [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-9                        [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-10                       [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-11                       [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-12                       [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-13                       [16, 197, 768]            (7,087,872)\n",
       "â”‚    â”‚    â””â”€Block: 3-14                       [16, 197, 768]            (7,087,872)\n",
       "â”‚    â””â”€LayerNorm: 2-6                         [16, 197, 768]            (1,536)\n",
       "â”‚    â””â”€Identity: 2-7                          [16, 768]                 --\n",
       "â”‚    â””â”€Dropout: 2-8                           [16, 768]                 --\n",
       "â”‚    â””â”€Identity: 2-9                          [16, 768]                 --\n",
       "â”œâ”€FireRisk_Head: 1-2                          [16, 7]                   --\n",
       "â”‚    â””â”€Module: 2-10                           --                        --\n",
       "â”‚    â”‚    â””â”€Linear: 3-15                      [16, 512]                 393,728\n",
       "â”‚    â”‚    â””â”€BatchNorm1d: 3-16                 [16, 512]                 1,024\n",
       "â”‚    â”‚    â””â”€Dropout: 3-17                     [16, 512]                 --\n",
       "â”‚    â””â”€Module: 2-11                           --                        --\n",
       "â”‚    â”‚    â””â”€Linear: 3-18                      [16, 128]                 65,664\n",
       "â”‚    â”‚    â””â”€BatchNorm1d: 3-19                 [16, 128]                 256\n",
       "â”‚    â”‚    â””â”€Dropout: 3-20                     [16, 128]                 --\n",
       "â”‚    â”‚    â””â”€Linear: 3-21                      [16, 7]                   903\n",
       "===============================================================================================\n",
       "Total params: 86,260,231\n",
       "Trainable params: 461,575\n",
       "Non-trainable params: 85,798,656\n",
       "Total mult-adds (G): 3.22\n",
       "===============================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 2595.10\n",
       "Params size (MB): 344.43\n",
       "Estimated Total Size (MB): 2949.16\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "full_model = FireRisk_Full(mae_model=mae_model, head_model=model, num_classes=7)\n",
    "summary(full_model, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e38645-65bc-40a6-be48-bfda687b0f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in globals() and model != None:\n",
    "    model.cpu()\n",
    "    del model\n",
    "if 'full_model' in globals() and full_model != None:\n",
    "    full_model.cpu()\n",
    "    del full_model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db449093-d22d-4dd8-9935-75485ce035b2",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189b240-dee3-43d8-a0a6-5e7098a1b50d",
   "metadata": {},
   "source": [
    "## Custom Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4efed8c1-1051-44bd-8d13-3267d3f5cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecayLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, total_epochs, warmup_epochs, sustain_epochs, factor, start_lr=0.000001, min_lr=0.000001, max_lr=0.001, last_epoch=-1):\n",
    "        self.total_epochs = total_epochs\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.sustain_epochs = sustain_epochs\n",
    "        self.factor = factor\n",
    "        self.start_lr = start_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        epoch = self.last_epoch\n",
    "        # Ramp-up phase\n",
    "        if epoch <= self.warmup_epochs:\n",
    "            lr = self.start_lr + (self.max_lr - self.start_lr) * (epoch / self.warmup_epochs)\n",
    "        # Sustain phase\n",
    "        elif epoch <= self.warmup_epochs + self.sustain_epochs:\n",
    "            lr = self.max_lr\n",
    "        # Decay phase\n",
    "        else:\n",
    "            lr = self.max_lr * self.factor ** (epoch - self.warmup_epochs - self.sustain_epochs)\n",
    "            lr = max(lr, self.min_lr)\n",
    "\n",
    "        return [lr] * len(self.base_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d67b5548-ecce-4537-85f1-6ef918cd4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPlateauLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, total_epochs, warmup_epochs, sustain_epochs, factor, patience, start_lr=0.000001, min_lr=0.000001, max_lr=0.001, last_epoch=-1):\n",
    "        self.total_epochs = total_epochs\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.sustain_epochs = sustain_epochs\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.start_lr = start_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.reduceLRFlag = False\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "        self.plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min',\n",
    "            factor=self.factor,\n",
    "            patience=self.patience,\n",
    "            min_lr=self.min_lr\n",
    "        )\n",
    "\n",
    "    def get_lr(self):\n",
    "        epoch = self.last_epoch\n",
    "        # Ramp-up phase\n",
    "        if epoch <= self.warmup_epochs:\n",
    "            lr = self.start_lr + (self.max_lr - self.start_lr) * (epoch / self.warmup_epochs)\n",
    "        # Sustain phase\n",
    "        elif epoch <= self.warmup_epochs + self.sustain_epochs:\n",
    "            lr = self.max_lr\n",
    "        # ReduceLROnPlateau\n",
    "        else:\n",
    "            self.reduceLRFlag = True\n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "        return [lr] * len(self.base_lrs)\n",
    "\n",
    "    def step(self, metric=None):\n",
    "        if self.reduceLRFlag:\n",
    "            self.plateau_scheduler.step(metric)\n",
    "        super().step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c744ab75-af19-4011-b3ee-4bf2131b2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, verbose=False, delta_metric='val_loss', start_epoch=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.delta_metric = delta_metric\n",
    "        self.best_metric = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.start_epoch = start_epoch\n",
    "        self.best_model_weights = None\n",
    "\n",
    "    def __call__(self, epoch, val_loss, val_accuracy):\n",
    "        current_metric = val_loss if self.delta_metric == 'val_loss' else val_accuracy\n",
    "\n",
    "        if epoch >= self.start_epoch:\n",
    "            if self.best_metric is None:\n",
    "                self.best_metric = current_metric\n",
    "                self.best_model_weights = model.state_dict()\n",
    "            elif current_metric < self.best_metric - self.min_delta:\n",
    "                self.best_metric = current_metric\n",
    "                self.best_model_weights = model.state_dict()\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "                    if self.verbose:\n",
    "                        print(f'Early stopping triggered! No improvement after {self.patience} epochs.')\n",
    "\n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d043e-1312-401a-afc1-b510f0ecd022",
   "metadata": {},
   "source": [
    "### Load latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7c94440-518f-4a9b-bfa8-180a48bb64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentDataset(Dataset):\n",
    "    def __init__(self, latents, labels, labels_cnt, filenames):\n",
    "        self.latents = latents\n",
    "        # self.glcm = glcm\n",
    "        # self.lbp = lbp\n",
    "        self.labels = labels\n",
    "        self.labels_cnt = labels_cnt\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.latents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        latent = self.latents[idx]\n",
    "        # glcm_feat = self.glcm[idx]\n",
    "        # lbp_feat = self.lbp[idx]\n",
    "        label = self.labels[idx]\n",
    "        label_cnt = self.labels_cnt[idx]\n",
    "        filename = self.filenames[idx]\n",
    "\n",
    "        # combined = torch.cat([latent, glcm_feat, lbp_feat], dim=0).float()\n",
    "\n",
    "        return latent, label, label_cnt, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b45739-9231-4f82-b64a-09de1616f907",
   "metadata": {},
   "source": [
    "## Load Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0088483f-e8fc-42b2-afd8-9d996b1d2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed latent representations and labels\n",
    "train_data = torch.load('outputs/train_latents.pth', weights_only=True)\n",
    "valid_data = torch.load('outputs/valid_latents.pth', weights_only=True)\n",
    "\n",
    "train_latents, train_labels, train_labels_cnt, train_filenames = train_data['latents'], train_data['labels'], train_data['labels_cnt'], train_data['filenames']\n",
    "valid_latents, valid_labels, valid_labels_cnt, valid_filenames = valid_data['latents'], valid_data['labels'], valid_data['labels_cnt'], valid_data['filenames']\n",
    "\n",
    "# Create DataLoaders using the precomputed latents\n",
    "train_lat_dataset = LatentDataset(train_latents, train_labels, train_labels_cnt, train_filenames)\n",
    "valid_lat_dataset = LatentDataset(valid_latents, valid_labels, valid_labels_cnt, valid_filenames)\n",
    "\n",
    "train_lat_loader = DataLoader(train_lat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_lat_loader = DataLoader(valid_lat_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a150b-a430-4687-85bc-238ef9537c3e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f2f4262-3221-4978-8f7a-ae56409e5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "start_lr = 0.0001\n",
    "min_lr = 0.000001\n",
    "max_lr = 0.001\n",
    "warmup_epochs = 9\n",
    "sustain_epochs = 0\n",
    "factor = 0.96\n",
    "epochs = 150\n",
    "\n",
    "weight = {\n",
    "    'cls': 1.0,\n",
    "    'reg': 0.2,\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=start_lr, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = CustomDecayLR(optimizer, epochs, warmup_epochs, sustain_epochs, factor, start_lr=start_lr, min_lr=min_lr, max_lr=max_lr)\n",
    "# lr_scheduler = CustomPlateauLR(optimizer, epochs, warmup_epochs, sustain_epochs, factor, patience=2, start_lr=start_lr, min_lr=min_lr, max_lr=max_lr)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, eta_min=min_lr)\n",
    "# early_stopping = EarlyStopping(patience=20, min_delta=0.0001, delta_metric='val_loss', start_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec2cdb-c74f-4706-90e9-2dba5089d7f3",
   "metadata": {},
   "source": [
    "### Use all train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f304047-517d-4d0c-9f97-652f148ab496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lat_dataset = ConcatDataset([train_lat_dataset, valid_lat_dataset])\n",
    "# train_lat_loader = DataLoader(train_lat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d048a3-c10b-4436-8644-f327557a4451",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91f396ab-b127-4b27-b1e0-d6502d1da262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear checkpoints\n",
    "checkpoints_path = 'outputs/run'\n",
    "\n",
    "for filename in os.listdir(checkpoints_path):\n",
    "    file_path = os.path.join(checkpoints_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d11d58f2-cc3c-4c6a-af4c-e231b4d6efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 214.52batch/s, accuracy=42, loss=1.3]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 363.36batch/s, accuracy=51.7, val_loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, loss: 1.5126, acc: 41.95%, val_loss: 1.2748, val_acc: 51.71%, lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 179.25batch/s, accuracy=49.3, loss=1.02]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 335.95batch/s, accuracy=53.3, val_loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, loss: 1.2919, acc: 49.30%, val_loss: 1.1849, val_acc: 53.34%, lr: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 176.11batch/s, accuracy=51.9, loss=1.44]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 331.28batch/s, accuracy=52.9, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, loss: 1.2253, acc: 51.89%, val_loss: 1.1609, val_acc: 52.95%, lr: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 193.92batch/s, accuracy=51.7, loss=1.2]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 433.26batch/s, accuracy=54.6, val_loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, loss: 1.2075, acc: 51.70%, val_loss: 1.1438, val_acc: 54.58%, lr: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 161.26batch/s, accuracy=52.9, loss=1.29]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 450.58batch/s, accuracy=53.6, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, loss: 1.1934, acc: 52.89%, val_loss: 1.1359, val_acc: 53.59%, lr: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 173.40batch/s, accuracy=52.5, loss=0.915]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 417.18batch/s, accuracy=53.9, val_loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, loss: 1.1706, acc: 52.50%, val_loss: 1.1397, val_acc: 53.87%, lr: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 212.69batch/s, accuracy=53.3, loss=1.39]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 433.23batch/s, accuracy=54.1, val_loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, loss: 1.1616, acc: 53.33%, val_loss: 1.1286, val_acc: 54.12%, lr: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 175.61batch/s, accuracy=52.7, loss=0.82]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 442.43batch/s, accuracy=54.5, val_loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, loss: 1.1650, acc: 52.68%, val_loss: 1.1197, val_acc: 54.48%, lr: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 178.53batch/s, accuracy=53.2, loss=0.983]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 390.19batch/s, accuracy=55.4, val_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, loss: 1.1633, acc: 53.17%, val_loss: 1.1144, val_acc: 55.37%, lr: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 157.82batch/s, accuracy=53.7, loss=1.14]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 392.89batch/s, accuracy=54.6, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, loss: 1.1405, acc: 53.74%, val_loss: 1.1092, val_acc: 54.58%, lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 185.15batch/s, accuracy=54.5, loss=1.21]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 417.19batch/s, accuracy=55.7, val_loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, loss: 1.1414, acc: 54.53%, val_loss: 1.1057, val_acc: 55.72%, lr: 0.00096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 196.87batch/s, accuracy=54.6, loss=1.23]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 363.36batch/s, accuracy=55.7, val_loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, loss: 1.1308, acc: 54.55%, val_loss: 1.0983, val_acc: 55.65%, lr: 0.0009216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 159.81batch/s, accuracy=54.6, loss=0.814]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 397.41batch/s, accuracy=54.8, val_loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, loss: 1.1173, acc: 54.65%, val_loss: 1.0992, val_acc: 54.80%, lr: 0.000884736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 167.81batch/s, accuracy=54.7, loss=1.11]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 374.06batch/s, accuracy=56.5, val_loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, loss: 1.1096, acc: 54.69%, val_loss: 1.0875, val_acc: 56.54%, lr: 0.000849347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 208.84batch/s, accuracy=55.3, loss=0.905]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 436.53batch/s, accuracy=56.4, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, loss: 1.1041, acc: 55.31%, val_loss: 1.0796, val_acc: 56.40%, lr: 0.000815373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 172.69batch/s, accuracy=55.9, loss=0.925]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 375.47batch/s, accuracy=56, val_loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, loss: 1.0856, acc: 55.95%, val_loss: 1.0915, val_acc: 55.97%, lr: 0.000782758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 190.27batch/s, accuracy=55.8, loss=1.13]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 402.28batch/s, accuracy=55.1, val_loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, loss: 1.0812, acc: 55.85%, val_loss: 1.0914, val_acc: 55.12%, lr: 0.000751447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 186.16batch/s, accuracy=56.7, loss=1.01]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 402.29batch/s, accuracy=56.3, val_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, loss: 1.0721, acc: 56.66%, val_loss: 1.0803, val_acc: 56.29%, lr: 0.00072139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 208.43batch/s, accuracy=56.9, loss=0.974]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 402.27batch/s, accuracy=56, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, loss: 1.0681, acc: 56.88%, val_loss: 1.0730, val_acc: 55.97%, lr: 0.000692534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 172.07batch/s, accuracy=57.4, loss=0.733]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 409.24batch/s, accuracy=56.1, val_loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, loss: 1.0619, acc: 57.41%, val_loss: 1.0783, val_acc: 56.08%, lr: 0.000664833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 172.37batch/s, accuracy=57.3, loss=0.779]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 375.46batch/s, accuracy=56, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, loss: 1.0500, acc: 57.29%, val_loss: 1.0728, val_acc: 56.01%, lr: 0.000638239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 153.87batch/s, accuracy=57.5, loss=1.11]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 398.16batch/s, accuracy=55.9, val_loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, loss: 1.0439, acc: 57.47%, val_loss: 1.0751, val_acc: 55.93%, lr: 0.00061271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 149.52batch/s, accuracy=57.9, loss=0.808]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 325.50batch/s, accuracy=57.1, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, loss: 1.0346, acc: 57.92%, val_loss: 1.0699, val_acc: 57.07%, lr: 0.000588201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 140.83batch/s, accuracy=58.3, loss=0.763]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 335.16batch/s, accuracy=57, val_loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, loss: 1.0327, acc: 58.29%, val_loss: 1.0680, val_acc: 57.00%, lr: 0.000564673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 151.16batch/s, accuracy=58.4, loss=1.23]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 406.40batch/s, accuracy=56.5, val_loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, loss: 1.0204, acc: 58.37%, val_loss: 1.0683, val_acc: 56.47%, lr: 0.000542086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 157.64batch/s, accuracy=59.1, loss=0.875]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 346.57batch/s, accuracy=57, val_loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, loss: 1.0123, acc: 59.11%, val_loss: 1.0656, val_acc: 57.04%, lr: 0.000520403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 176.48batch/s, accuracy=59.4, loss=0.966]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 352.65batch/s, accuracy=56.8, val_loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, loss: 1.0103, acc: 59.41%, val_loss: 1.0576, val_acc: 56.75%, lr: 0.000499587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 173.53batch/s, accuracy=59.1, loss=0.907]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 413.70batch/s, accuracy=57.1, val_loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, loss: 1.0029, acc: 59.12%, val_loss: 1.0612, val_acc: 57.11%, lr: 0.000479603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 174.32batch/s, accuracy=59.6, loss=0.98]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 406.08batch/s, accuracy=57, val_loss=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, loss: 1.0003, acc: 59.58%, val_loss: 1.0605, val_acc: 57.00%, lr: 0.000460419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 144.22batch/s, accuracy=59.6, loss=0.863]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 340.46batch/s, accuracy=57.6, val_loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, loss: 0.9924, acc: 59.57%, val_loss: 1.0539, val_acc: 57.60%, lr: 0.000442002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 164.45batch/s, accuracy=59.8, loss=1.37]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 414.33batch/s, accuracy=57.5, val_loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, loss: 0.9891, acc: 59.76%, val_loss: 1.0549, val_acc: 57.50%, lr: 0.000424322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 160.97batch/s, accuracy=60.1, loss=0.841]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 413.57batch/s, accuracy=56.9, val_loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, loss: 0.9773, acc: 60.12%, val_loss: 1.0648, val_acc: 56.86%, lr: 0.000407349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 155.11batch/s, accuracy=60.5, loss=1.16]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 415.05batch/s, accuracy=57.7, val_loss=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, loss: 0.9649, acc: 60.51%, val_loss: 1.0594, val_acc: 57.75%, lr: 0.000391055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 158.23batch/s, accuracy=60.5, loss=0.911]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 375.73batch/s, accuracy=57.3, val_loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, loss: 0.9639, acc: 60.53%, val_loss: 1.0668, val_acc: 57.32%, lr: 0.000375413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 177.58batch/s, accuracy=61.1, loss=0.662]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 406.56batch/s, accuracy=57.7, val_loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, loss: 0.9539, acc: 61.14%, val_loss: 1.0691, val_acc: 57.75%, lr: 0.000360397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 172.19batch/s, accuracy=60.7, loss=0.815]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 406.89batch/s, accuracy=57.7, val_loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, loss: 0.9552, acc: 60.65%, val_loss: 1.0693, val_acc: 57.71%, lr: 0.000345981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 144.51batch/s, accuracy=62, loss=1.13]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 335.32batch/s, accuracy=57.6, val_loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, loss: 0.9466, acc: 61.97%, val_loss: 1.0653, val_acc: 57.64%, lr: 0.000332142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 177.92batch/s, accuracy=61.1, loss=0.685]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 398.80batch/s, accuracy=57.9, val_loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, loss: 0.9535, acc: 61.15%, val_loss: 1.0631, val_acc: 57.89%, lr: 0.000318856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 158.59batch/s, accuracy=61.7, loss=0.897]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 403.90batch/s, accuracy=57.2, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, loss: 0.9375, acc: 61.69%, val_loss: 1.0756, val_acc: 57.18%, lr: 0.000306102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 154.49batch/s, accuracy=61.5, loss=1.52]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 413.96batch/s, accuracy=57.9, val_loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, loss: 0.9427, acc: 61.49%, val_loss: 1.0610, val_acc: 57.92%, lr: 0.000293858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:03<00:00, 199.95batch/s, accuracy=62.3, loss=0.97]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 408.19batch/s, accuracy=57.9, val_loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, loss: 0.9257, acc: 62.26%, val_loss: 1.0686, val_acc: 57.89%, lr: 0.000282103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 161.84batch/s, accuracy=62.8, loss=0.851]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 422.84batch/s, accuracy=58.1, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, loss: 0.9195, acc: 62.77%, val_loss: 1.0688, val_acc: 58.07%, lr: 0.000270819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 161.38batch/s, accuracy=61.8, loss=1.01]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 415.52batch/s, accuracy=57, val_loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, loss: 0.9199, acc: 61.82%, val_loss: 1.0804, val_acc: 57.00%, lr: 0.000259986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 164.01batch/s, accuracy=62.5, loss=0.942]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 406.04batch/s, accuracy=58.1, val_loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, loss: 0.9140, acc: 62.51%, val_loss: 1.0640, val_acc: 58.10%, lr: 0.000249587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 173.92batch/s, accuracy=62.8, loss=1.11]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 330.02batch/s, accuracy=57.8, val_loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, loss: 0.9039, acc: 62.82%, val_loss: 1.0722, val_acc: 57.78%, lr: 0.000239603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 162.07batch/s, accuracy=62.9, loss=0.756]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 413.47batch/s, accuracy=58, val_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, loss: 0.9133, acc: 62.86%, val_loss: 1.0748, val_acc: 57.96%, lr: 0.000230019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 150.95batch/s, accuracy=63.1, loss=0.775]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 406.93batch/s, accuracy=58.1, val_loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, loss: 0.8995, acc: 63.10%, val_loss: 1.0697, val_acc: 58.07%, lr: 0.000220819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 158.62batch/s, accuracy=63.5, loss=0.727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 413.65batch/s, accuracy=58.1, val_loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, loss: 0.8907, acc: 63.53%, val_loss: 1.0738, val_acc: 58.07%, lr: 0.000211986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 164.45batch/s, accuracy=63.1, loss=0.82]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 350.60batch/s, accuracy=58, val_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, loss: 0.9008, acc: 63.08%, val_loss: 1.0810, val_acc: 58.00%, lr: 0.000203506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703/703 [00:04<00:00, 171.58batch/s, accuracy=63.8, loss=1.1]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 398.15batch/s, accuracy=58.4, val_loss=1.47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, loss: 0.8884, acc: 63.83%, val_loss: 1.0695, val_acc: 58.42%, lr: 0.000195366\n",
      "Early stopping triggered! Loading best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to save metrics history\n",
    "history = {\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'val_losses': [],\n",
    "    'val_accuracies': [],\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # # Create DataLoaders using the precomputed latents for each epoch\n",
    "    # train_lat_dataset = LatentDataset(train_latents[epoch%50], train_labels, train_labels_cnt, train_filenames)\n",
    "    # train_lat_loader = DataLoader(train_lat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    with tqdm(train_lat_loader, unit=\"batch\") as tepoch:\n",
    "        \n",
    "        # for images, targets_cls, targets_reg, _ in tepoch:\n",
    "        #     images, targets_cls, targets_reg = images.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "\n",
    "        for latents, targets_cls, targets_reg, _ in tepoch:\n",
    "            latents, targets_cls, targets_reg = latents.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs_cls = model(latents)\n",
    "\n",
    "            # Compute losses\n",
    "            loss = criterion_cls(outputs_cls, targets_cls)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs_cls, 1)\n",
    "            total_train += targets_cls.size(0)\n",
    "            correct_train += (predicted == targets_cls).sum().item()\n",
    "\n",
    "            # Update the progress bar\n",
    "            tepoch.set_postfix(\n",
    "                loss=loss.item(),\n",
    "                accuracy=100 * correct_train / total_train\n",
    "            )\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_lat_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients for validation\n",
    "        with tqdm(valid_lat_loader, unit=\"batch\") as tepoch_val:\n",
    "            \n",
    "            # for images, targets_cls, targets_reg, _ in tepoch_val:\n",
    "            #     images, targets_cls, targets_reg = images.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "                \n",
    "            for latents, targets_cls, targets_reg, _ in tepoch_val:\n",
    "                latents, targets_cls, targets_reg = latents.to(device), targets_cls.to(device), targets_reg.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs_cls = model(latents)\n",
    "\n",
    "                # Compute losses\n",
    "                loss = criterion_cls(outputs_cls, targets_cls)\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs_cls, 1)\n",
    "                total_val += targets_cls.size(0)\n",
    "                correct_val += (predicted == targets_cls).sum().item()\n",
    "\n",
    "                # Update the progress bar\n",
    "                tepoch_val.set_postfix(\n",
    "                    val_loss=loss.item(),\n",
    "                    accuracy=100 * correct_val / total_val\n",
    "                )\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(valid_lat_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, loss: {avg_train_loss:.4f}, acc: {train_accuracy:.2f}%, val_loss: {avg_val_loss:.4f}, val_acc: {val_accuracy:.2f}%, lr: {current_lr:.6g}')\n",
    "    \n",
    "    # Save the metrics\n",
    "    history['train_losses'].append(avg_train_loss)\n",
    "    history['train_accuracies'].append(train_accuracy)\n",
    "    history['val_losses'].append(avg_val_loss)\n",
    "    history['val_accuracies'].append(val_accuracy)\n",
    "    \n",
    "    # Step the scheduler after each epoch\n",
    "    lr_scheduler.step()\n",
    "    # lr_scheduler.step(metric=avg_val_loss)\n",
    "\n",
    "    # Save each epoch's model\n",
    "    torch.save(model.state_dict(), 'outputs/run/model_epoch_' + str(epoch) + '.pth')\n",
    "\n",
    "    # Check early stopping after each epoch\n",
    "    if early_stopping(epoch, avg_val_loss, val_accuracy):\n",
    "        print(\"Early stopping triggered! Loading best model.\")\n",
    "        # Save the last model weights\n",
    "        torch.save(model.state_dict(), 'outputs/last_head_model.pth')\n",
    "        # Load the best model weights\n",
    "        model.load_state_dict(early_stopping.best_model_weights)\n",
    "        break\n",
    "\n",
    "# Save the best model weights\n",
    "torch.save(model.state_dict(), 'outputs/best_head_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a7cdb-897c-4461-8110-5fdd895bcb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses and Accuracies\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses'], label='Train Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_accuracies'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracies'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2809e24-ad8e-4a1f-862d-e8b5d8778637",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57ffef9c-7f98-4aa8-9f62-020635902528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed latent representations and labels\n",
    "test_data = torch.load('outputs/test_latents.pth', weights_only=True)\n",
    "test_latents, test_labels, test_labels_cnt, test_filenames = test_data['latents'], test_data['labels'], test_data['labels_cnt'], test_data['filenames']\n",
    "\n",
    "# Create DataLoaders using the precomputed latents\n",
    "test_lat_dataset = LatentDataset(test_latents, test_labels, test_labels_cnt, test_filenames)\n",
    "test_lat_loader = DataLoader(test_lat_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "366bba86-c2dc-4011-9962-a2205876c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_4224\\1297779379.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('outputs/best_head_model.pth')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the FireRisk_Head model\n",
    "model = FireRisk_Head(num_classes=7)\n",
    "checkpoint = torch.load('outputs/best_head_model.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "\n",
    "# # Initialize the combined model with the MAE encoder and FireRisk_Head weights\n",
    "# full_model = FireRisk_Full(mae_model=mae_model, head_model=model, num_classes=7)\n",
    "# full_model = full_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f1243df-5abe-4705-90c4-5bdea63adb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "            for images, targets, _, filenames in tepoch:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(targets.cpu().numpy())\n",
    "                all_filenames.extend(filenames)\n",
    "\n",
    "                # Update the tqdm progress bar\n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy, all_preds, all_labels, all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38afe3b8-ecc5-4c97-b1c5-6a415c8d3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_4224\\393263947.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('outputs/run/model_epoch_' + str(i) + '.pth')\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:04<00:00, 333.73batch/s, accuracy=57.2, loss=0.175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Test Loss: 1.1995, Test Accuracy: 57.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 357.58batch/s, accuracy=58.6, loss=0.0879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Test Loss: 1.1118, Test Accuracy: 58.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 355.26batch/s, accuracy=56.3, loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Test Loss: 1.1191, Test Accuracy: 56.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 353.02batch/s, accuracy=58.4, loss=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Test Loss: 1.0891, Test Accuracy: 58.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 354.36batch/s, accuracy=57.6, loss=0.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Test Loss: 1.0917, Test Accuracy: 57.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 353.60batch/s, accuracy=57.8, loss=0.00891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Test Loss: 1.0915, Test Accuracy: 57.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 355.17batch/s, accuracy=58.7, loss=0.0222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Test Loss: 1.0760, Test Accuracy: 58.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 364.10batch/s, accuracy=59.6, loss=0.00617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Test Loss: 1.0598, Test Accuracy: 59.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 364.22batch/s, accuracy=58.1, loss=0.000769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Test Loss: 1.0769, Test Accuracy: 58.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 363.04batch/s, accuracy=58, loss=0.0194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Test Loss: 1.0905, Test Accuracy: 57.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 363.01batch/s, accuracy=59.8, loss=0.00113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Test Loss: 1.0506, Test Accuracy: 59.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 362.32batch/s, accuracy=58.1, loss=0.00582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Test Loss: 1.0659, Test Accuracy: 58.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 367.43batch/s, accuracy=58.9, loss=0.00748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Test Loss: 1.0719, Test Accuracy: 58.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 364.63batch/s, accuracy=59.8, loss=0.00806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Test Loss: 1.0495, Test Accuracy: 59.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 363.07batch/s, accuracy=59.3, loss=0.00818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Test Loss: 1.0565, Test Accuracy: 59.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 362.77batch/s, accuracy=58.7, loss=0.0022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Test Loss: 1.0551, Test Accuracy: 58.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 358.58batch/s, accuracy=58.7, loss=0.00383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Test Loss: 1.0508, Test Accuracy: 58.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 362.52batch/s, accuracy=59.2, loss=0.00312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Test Loss: 1.0491, Test Accuracy: 59.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 364.78batch/s, accuracy=58.8, loss=0.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Test Loss: 1.0498, Test Accuracy: 58.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 363.77batch/s, accuracy=58.8, loss=0.00213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Test Loss: 1.0552, Test Accuracy: 58.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 366.45batch/s, accuracy=59.9, loss=0.00466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Test Loss: 1.0329, Test Accuracy: 59.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 369.47batch/s, accuracy=60.1, loss=0.000885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Test Loss: 1.0263, Test Accuracy: 60.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 362.59batch/s, accuracy=58.5, loss=0.00742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Test Loss: 1.0478, Test Accuracy: 58.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 368.52batch/s, accuracy=59.3, loss=0.00163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Test Loss: 1.0445, Test Accuracy: 59.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 351.68batch/s, accuracy=58.4, loss=0.00526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Test Loss: 1.0538, Test Accuracy: 58.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 362.31batch/s, accuracy=59.8, loss=0.00217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Test Loss: 1.0340, Test Accuracy: 59.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 371.57batch/s, accuracy=59.6, loss=0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Test Loss: 1.0356, Test Accuracy: 59.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 364.47batch/s, accuracy=59.1, loss=0.00129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Test Loss: 1.0374, Test Accuracy: 59.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 374.81batch/s, accuracy=60.4, loss=0.00405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Test Loss: 1.0353, Test Accuracy: 60.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 378.98batch/s, accuracy=60.4, loss=0.00706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Test Loss: 1.0290, Test Accuracy: 60.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 369.62batch/s, accuracy=60.5, loss=0.0022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Test Loss: 1.0227, Test Accuracy: 60.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 370.36batch/s, accuracy=59.2, loss=0.00482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Test Loss: 1.0397, Test Accuracy: 59.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 365.30batch/s, accuracy=59.6, loss=0.00767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Test Loss: 1.0415, Test Accuracy: 59.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 367.07batch/s, accuracy=59.4, loss=0.00582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Test Loss: 1.0583, Test Accuracy: 59.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 356.91batch/s, accuracy=60.2, loss=0.00129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Test Loss: 1.0330, Test Accuracy: 60.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 367.45batch/s, accuracy=60, loss=0.00662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Test Loss: 1.0387, Test Accuracy: 59.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 374.82batch/s, accuracy=59.9, loss=0.000793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Test Loss: 1.0382, Test Accuracy: 59.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 365.30batch/s, accuracy=59.3, loss=0.00368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Test Loss: 1.0555, Test Accuracy: 59.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 357.76batch/s, accuracy=58.3, loss=0.00212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Test Loss: 1.0605, Test Accuracy: 58.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 353.24batch/s, accuracy=59.7, loss=0.00208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Test Loss: 1.0429, Test Accuracy: 59.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 345.20batch/s, accuracy=59.9, loss=0.00228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Test Loss: 1.0521, Test Accuracy: 59.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 347.56batch/s, accuracy=60.3, loss=0.00765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Test Loss: 1.0309, Test Accuracy: 60.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 346.59batch/s, accuracy=59, loss=0.000705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Test Loss: 1.0668, Test Accuracy: 59.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 367.29batch/s, accuracy=60.1, loss=0.00111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Test Loss: 1.0403, Test Accuracy: 60.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 378.26batch/s, accuracy=59.6, loss=0.0016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Test Loss: 1.0518, Test Accuracy: 59.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 371.59batch/s, accuracy=59, loss=0.00116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Test Loss: 1.0618, Test Accuracy: 59.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 373.61batch/s, accuracy=59.6, loss=0.00156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Test Loss: 1.0615, Test Accuracy: 59.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 374.99batch/s, accuracy=59.2, loss=0.00163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Test Loss: 1.0652, Test Accuracy: 59.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 371.22batch/s, accuracy=58.1, loss=0.00247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Test Loss: 1.0873, Test Accuracy: 58.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:03<00:00, 380.12batch/s, accuracy=59.6, loss=0.0011]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Test Loss: 1.0634, Test Accuracy: 59.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test dataset\n",
    "all_test_loss = []\n",
    "all_test_accuracy = []\n",
    "all_test_preds = []\n",
    "all_test_labels = []\n",
    "all_test_filenames = []\n",
    "\n",
    "epochs_count = sum(\n",
    "    1 for filename in os.listdir(checkpoints_path)\n",
    "    if os.path.isfile(os.path.join(checkpoints_path, filename))\n",
    ")\n",
    "\n",
    "for i in range(epochs_count):\n",
    "    checkpoint = torch.load('outputs/run/model_epoch_' + str(i) + '.pth')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    test_loss, test_accuracy, test_preds, test_labels, test_filenames = evaluate(model, test_lat_loader, criterion_cls, device)\n",
    "    all_test_loss.append(test_loss)\n",
    "    all_test_accuracy.append(test_accuracy)\n",
    "    all_test_preds.append(test_preds)\n",
    "    all_test_labels.append(test_labels)\n",
    "    all_test_filenames.append(test_filenames)\n",
    "    print(f\"Epoch {i+1}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9846de-85fc-41f8-9bdb-8ebf2e71bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses and Accuracies\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_test_loss, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Testing Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_test_accuracy, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Testing Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf5858-bb17-44e4-9b9a-d30821a77698",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d64852c-fcf7-4e2b-8203-8406c1ea36cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch with highest accuracy: 31\n"
     ]
    }
   ],
   "source": [
    "# Search the best performing epoch\n",
    "best_epoch = all_test_accuracy.index(max(all_test_accuracy))\n",
    "print(\"Epoch with highest accuracy:\", best_epoch+1)\n",
    "test_loss, test_accuracy, test_preds, test_labels, test_filenames = all_test_loss[best_epoch], all_test_accuracy[best_epoch], all_test_preds[best_epoch], all_test_labels[best_epoch], all_test_filenames[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55abec-b0a6-42d3-82ca-f507cafd9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bb2d613-4077-4a9a-a8ad-48a7b296ec47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9086    0.8168    0.8602       584\n",
      "           1     0.7791    0.8627    0.8188      5091\n",
      "           2     0.6447    0.7898    0.7099      8448\n",
      "           3     0.3245    0.1601    0.2144      2599\n",
      "           4     0.1855    0.1287    0.1519      1772\n",
      "           5     0.3269    0.3586    0.3420      1609\n",
      "           6     0.3634    0.1905    0.2500      1438\n",
      "\n",
      "    accuracy                         0.6052     21541\n",
      "   macro avg     0.5047    0.4724    0.4782     21541\n",
      "weighted avg     0.5647    0.6052    0.5758     21541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(test_labels, test_preds, digits=4)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5033f38-e3b7-4cd7-a852-9457eb631e39",
   "metadata": {},
   "source": [
    "### Save session results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "048e83ca-3ac9-4a6e-9516-f9d3068bde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame({\n",
    "    'Filename': test_filenames,\n",
    "    'Label': test_labels,\n",
    "    'Prediction': test_preds\n",
    "})\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "test_results.to_csv('outputs/test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea48c9ad-bf5c-46f1-9a0e-50d70a80653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv('outputs/history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd9a2917-0e25-4564-9f4a-227ff8ae0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_results = pd.DataFrame({\n",
    "    'all_test_loss': all_test_loss,\n",
    "    'all_test_accuracy': all_test_accuracy\n",
    "})\n",
    "all_test_results.to_csv('outputs/all_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc609be5-5384-40b2-9124-335b456267e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
